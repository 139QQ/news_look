<!-- Generated by SpecStory -->

# 日志文件管理与删除问题修复 (2025-04-24 20:34:11)

_**User**_

日志无法正常删除到指定文件，请修复问题

---

_**Assistant**_

根据您提供的日志文件，我发现这个问题与日志文件积累有关。日志文件似乎在不断追加内容而没有正常删除或轮转。以下是解决方案：

## 日志文件管理问题分析

1. 您的日志文件 `东方财富_20250424.log` 显示了多次初始化日志记录器的信息，但没有任何删除或轮转机制
2. 每次运行程序时，新的日志内容都被追加到现有文件中

## 解决方案

### 1. 修改日志配置，添加轮转机制

```python
import logging
from logging.handlers import RotatingFileHandler, TimedRotatingFileHandler
import os

def setup_logger(source_name):
    # 确保日志目录存在
    log_dir = os.path.join('logs', source_name)
    os.makedirs(log_dir, exist_ok=True)
    
    # 日志文件路径
    log_file = os.path.join(log_dir, f'{source_name}_%Y%m%d.log')
    
    # 创建日志记录器
    logger = logging.getLogger(f'crawler.{source_name}')
    logger.setLevel(logging.INFO)
    
    # 清除现有处理器
    if logger.handlers:
        logger.handlers.clear()
    
    # 添加按日期轮转的文件处理器
    file_handler = TimedRotatingFileHandler(
        log_file,
        when='midnight',
        interval=1,
        backupCount=7,  # 保留7天的日志
        encoding='utf-8'
    )
    
    # 设置日志格式
    formatter = logging.Formatter('%(asctime)s [%(levelname)s] [%(name)s] %(message)s')
    file_handler.setFormatter(formatter)
    
    # 添加处理器到日志记录器
    logger.addHandler(file_handler)
    
    # 记录初始化信息
    logger.info(f'爬虫日志记录器 \'{source_name}\' 已初始化，日志文件: {os.path.abspath(log_file)}')
    
    return logger
```

### 2. 添加日志清理功能

```python
def clean_old_logs(source_name, days_to_keep=7):
    """清理指定天数前的日志文件"""
    import time
    from datetime import datetime, timedelta
    
    log_dir = os.path.join('logs', source_name)
    if not os.path.exists(log_dir):
        return
    
    # 计算保留日期的时间戳
    cutoff_date = datetime.now() - timedelta(days=days_to_keep)
    cutoff_timestamp = cutoff_date.timestamp()
    
    # 遍历并删除旧日志
    for filename in os.listdir(log_dir):
        file_path = os.path.join(log_dir, filename)
        if os.path.isfile(file_path):
            file_timestamp = os.path.getmtime(file_path)
            if file_timestamp < cutoff_timestamp:
                try:
                    os.remove(file_path)
                    print(f"已删除旧日志文件: {file_path}")
                except Exception as e:
                    print(f"删除日志文件 {file_path} 失败: {str(e)}")
```

### 3. 在爬虫初始化时调用日志清理

在爬虫初始化代码中添加日志清理调用：

```python
# 爬虫初始化时
clean_old_logs('东方财富')
logger = setup_logger('东方财富')
```

### 4. 添加日志管理脚本

创建一个单独的脚本进行日志管理：

```python
# scripts/log_manager.py
import os
import time
from datetime import datetime, timedelta
import argparse

def clean_logs(base_dir='logs', days_to_keep=7, source=None):
    """清理指定天数前的日志文件"""
    if not os.path.exists(base_dir):
        print(f"日志目录 {base_dir} 不存在")
        return
    
    # 计算保留日期的时间戳
    cutoff_date = datetime.now() - timedelta(days=days_to_keep)
    cutoff_timestamp = cutoff_date.timestamp()
    
    sources = [source] if source else os.listdir(base_dir)
    
    for src in sources:
        log_dir = os.path.join(base_dir, src)
        if not os.path.exists(log_dir) or not os.path.isdir(log_dir):
            continue
        
        deleted_count = 0
        for filename in os.listdir(log_dir):
            file_path = os.path.join(log_dir, filename)
            if os.path.isfile(file_path):
                file_timestamp = os.path.getmtime(file_path)
                if file_timestamp < cutoff_timestamp:
                    try:
                        os.remove(file_path)
                        deleted_count += 1
                    except Exception as e:
                        print(f"删除日志文件 {file_path} 失败: {str(e)}")
        
        print(f"来源 {src}: 已删除 {deleted_count} 个旧日志文件")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="日志文件管理工具")
    parser.add_argument("--days", type=int, default=7, help="要保留的日志天数")
    parser.add_argument("--source", type=str, help="指定要清理的来源，不指定则清理所有")
    
    args = parser.parse_args()
    clean_logs(days_to_keep=args.days, source=args.source)
```

使用方法：
```
python scripts/log_manager.py --days 7 --source 东方财富
```

这些修改将确保您的日志文件按日期自动轮转，并且可以定期清理旧日志，避免日志文件无限增长。

---

_**User**_

无法正常输出

---

_**Assistant**_

从日志输出可以看到存在明显的重复日志问题，每条日志信息都被记录了两次，而且格式不一致。这表明您有两个日志处理器在同时工作，导致输出重复。问题分析如下：

## 日志重复输出问题分析

1. 每条日志输出两次，一次带毫秒(如 `20:35:17,794`)，一次不带毫秒(如 `20:35:17`)
2. 格式也略有不同：一个使用方括号 `[INFO]`，另一个在前面有时间戳
3. 这表明您同时配置了两个日

---



---

