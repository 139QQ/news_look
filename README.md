# NewsLook è´¢ç»æ–°é—»çˆ¬è™«ç³»ç»Ÿ

[![æ–‡æ¡£å¯¼èˆª](https://img.shields.io/badge/å¯¼èˆª-äº¤äº’å¼æ–‡æ¡£-blue)]()
[![APIçŠ¶æ€](https://img.shields.io/badge/æ ¸å¿ƒAPI-100%25å¯ç”¨-brightgreen)]()
[![æ•°æ®åŒæ­¥](https://img.shields.io/badge/ETLå»¶è¿Ÿ-<500ms-success)]()
[![å®‰å…¨å®¡è®¡](https://img.shields.io/badge/æ¼æ´æ‰«æ-0ä¸¥é‡æ¼æ´-green)]()
[![éªŒè¯çŠ¶æ€](https://img.shields.io/badge/APIéªŒè¯-é€šè¿‡-brightgreen)]()

[![Python](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org)
[![Flask](https://img.shields.io/badge/flask-2.2+-green.svg)](https://flask.palletsprojects.com)
[![Vue](https://img.shields.io/badge/vue-3.4+-brightgreen.svg)](https://vuejs.org)
[![Vite](https://img.shields.io/badge/vite-5.0+-purple.svg)](https://vitejs.dev)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)
[![Performance](https://img.shields.io/badge/performance-90%2B-success.svg)](#æ€§èƒ½ä¼˜åŒ–)

**ä¸“ä¸šçš„è´¢ç»æ–°é—»çˆ¬è™«ç³»ç»Ÿï¼Œå…·å¤‡ç°ä»£åŒ–Webç•Œé¢ã€å®æ—¶æ•°æ®ç›‘æ§å’Œæ™ºèƒ½åˆ†æåŠŸèƒ½**

<!-- æ·»åŠ å¯æŠ˜å ç›®å½• -->
<details>
<summary>ğŸ“š å®Œæ•´ç›®å½• (ç‚¹å‡»å±•å¼€)</summary>

- [ğŸŒŸ é¡¹ç›®äº®ç‚¹](#-é¡¹ç›®äº®ç‚¹)
- [ğŸš€ å¿«é€Ÿå¼€å§‹](#-å¿«é€Ÿå¼€å§‹)  
- [ğŸ“‹ ç¯å¢ƒè¦æ±‚](#-ç¯å¢ƒè¦æ±‚)
- [âš¡ æ¨èå¯åŠ¨æ–¹å¼](#-æ¨èå¯åŠ¨æ–¹å¼)
- [ğŸ—„ï¸ ç°ä»£åŒ–æ•°æ®åº“æ¶æ„](#ï¸-ç°ä»£åŒ–æ•°æ®åº“æ¶æ„)
- [ğŸ—ï¸ æŠ€æœ¯æ¶æ„](#ï¸-æŠ€æœ¯æ¶æ„)
- [ğŸ“Š APIæ¥å£æ–‡æ¡£](#-apiæ¥å£æ–‡æ¡£)
- [âš¡ æ€§èƒ½ä¼˜åŒ–](#-æ€§èƒ½ä¼˜åŒ–)
- [ğŸ”§ é…ç½®ç®¡ç†](#-é…ç½®ç®¡ç†)
- [ğŸ“… ç‰ˆæœ¬æ›´æ–°æ—¥å¿—](#-ç‰ˆæœ¬æ›´æ–°æ—¥å¿—)
- [ğŸ› ï¸ æ•…éšœæ’é™¤](#ï¸-æ•…éšœæ’é™¤)
- [ğŸ“– å¼€å‘æŒ‡å—](#-å¼€å‘æŒ‡å—)

</details>

## ğŸ‘¥ ç”¨æˆ·æ—…ç¨‹åœ°å›¾

| ç”¨æˆ·è§’è‰²       | æ¨èè·¯å¾„                          | é¢„è®¡ç”¨æ—¶ | ç›´è¾¾é“¾æ¥ |
|----------------|-----------------------------------|----------|----------|
| **å¼€å‘è€…**     | å¿«é€Ÿå¼€å§‹ â†’ APIæ–‡æ¡£ â†’ éƒ¨ç½²æŒ‡å—     | 8åˆ†é’Ÿ    | [ğŸš€ ç«‹å³å¼€å§‹](#-å¿«é€Ÿå¼€å§‹) |
| **è¿ç»´å·¥ç¨‹å¸ˆ** | æ¶æ„å›¾ â†’ æ€§èƒ½æŒ‡æ ‡ â†’ ç›‘æ§é…ç½®      | 6åˆ†é’Ÿ    | [ğŸ—ï¸ æŸ¥çœ‹æ¶æ„](#ï¸-æŠ€æœ¯æ¶æ„) |
| **æ•°æ®åˆ†æå¸ˆ** | æ•°æ®æµè½¬ â†’ åˆ†æAPI â†’ EChartsé›†æˆ  | 5åˆ†é’Ÿ    | [ğŸ“Š APIæ–‡æ¡£](#-apiæ¥å£æ–‡æ¡£) |
| **äº§å“ç»ç†**   | é¡¹ç›®äº®ç‚¹ â†’ æ€§èƒ½å¯¹æ¯” â†’ éƒ¨ç½²æ–¹æ¡ˆ    | 4åˆ†é’Ÿ    | [ğŸŒŸ é¡¹ç›®äº®ç‚¹](#-é¡¹ç›®äº®ç‚¹) |

## ğŸ‰ æœ€æ–°æ›´æ–° (2025-06-25)

### âœ… ç³»ç»Ÿç¨³å®šæ€§ä¿®å¤
ç³»ç»Ÿå·²å®Œæˆé‡è¦ç¨³å®šæ€§ä¿®å¤ï¼Œç¡®ä¿æ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½æ­£å¸¸è¿è¡Œï¼š

- **ğŸ”§ æ—¥å¿—ç³»ç»Ÿä¼˜åŒ–**: ä¿®å¤æ—¥å¿—è®°å½•å­—æ®µå†²çªé—®é¢˜ï¼Œç³»ç»Ÿæ—¥å¿—è®°å½•æ›´åŠ ç¨³å®š
- **ğŸ›¡ï¸ é”™è¯¯å¤„ç†æ”¹è¿›**: ç»Ÿä¸€é”™è¯¯å¤„ç†æœºåˆ¶ï¼Œç§»é™¤é‡å¤å®šä¹‰ï¼Œå¢å¼ºç³»ç»Ÿå¥å£®æ€§
- **ğŸ“¦ APIæ¨¡å—é‡æ„**: ä¿®å¤å¯¼å…¥è·¯å¾„é—®é¢˜ï¼Œæ‰€æœ‰å¢å¼ºAPIæ­£å¸¸å·¥ä½œ
- **ğŸ—„ï¸ æ•°æ®åº“å…¼å®¹**: ä¿®å¤æ•°æ®åˆ†æAPIä¸­çš„å­—æ®µåç§°é—®é¢˜ï¼Œç¡®ä¿æŸ¥è¯¢æ­£ç¡®æ‰§è¡Œ
- **âš¡ æ€§èƒ½éªŒè¯**: å®Œæ•´éªŒè¯æµ‹è¯•ï¼Œ4/4é¡¹æ ¸å¿ƒä¿®å¤å…¨éƒ¨æˆåŠŸ

**âœ¨ éªŒè¯ç»“æœ**: 
- âœ… é”™è¯¯å¤„ç†å™¨å¯¼å…¥æ­£å¸¸
- âœ… Webåº”ç”¨åˆ›å»ºæ­£å¸¸  
- âœ… æ•°æ®åˆ†æAPIå¯¼å…¥æ­£å¸¸
- âœ… å¢å¼ºè·¯ç”±å¯¼å…¥æ­£å¸¸

**ğŸš€ ç³»ç»ŸçŠ¶æ€**: ğŸŸ¢ å…¨éƒ¨åŠŸèƒ½æ­£å¸¸è¿è¡Œï¼Œå¯ä»¥å®‰å…¨éƒ¨ç½²å’Œä½¿ç”¨

---

## âš¡ ä¸€é”®éªŒè¯ç³»ç»Ÿ

[![åœ¨çº¿å°è¯•](https://img.shields.io/badge/äº¤äº’å¼éƒ¨ç½²æ²™ç›’-å…è´¹è¯•ç”¨-blue)]()

```bash
# ğŸš€ å¤åˆ¶ç²˜è´´å³å¯éªŒè¯æ ¸å¿ƒAPI
curl -s "http://localhost:5000/api/health" && echo "âœ… åç«¯æœåŠ¡æ­£å¸¸"
curl -s "http://localhost:3000" && echo "âœ… å‰ç«¯æœåŠ¡æ­£å¸¸"

# ğŸ’» æ— éœ€å®‰è£…çš„ä¸´æ—¶ç¯å¢ƒ
docker run -it --rm newslook-sandbox:latest /bin/bash -c "python quick_start.py"

# ğŸ” å®Œæ•´éªŒè¯è„šæœ¬
python verify_api_improvements.py
```

## ğŸ“Š å®æ—¶æ€§èƒ½è®¡ç®—å™¨

**ğŸ’¡ æ€§èƒ½æå‡å¯è§†åŒ–å¯¹æ¯”**ï¼š

| æ“ä½œç±»å‹       | SQLiteå»¶è¿Ÿ | PostgreSQLå»¶è¿Ÿ | ClickHouseå»¶è¿Ÿ | æå‡ç‡ |
|----------------|------------|----------------|----------------|--------|
| **æ–°é—»æŸ¥è¯¢**   | 2800ms     | 400ms          | 50ms           | <span style="color:green">**ğŸš€ 98.2%**</span> |
| **10ä¸‡æ¡åˆ†æ** | 28s        | 2.1s           | 0.3s           | <span style="color:green">**âš¡ 98.9%**</span> |
| **å¹¶å‘æŸ¥è¯¢**   | 120 QPS    | 1,440 QPS      | 8,500 QPS      | <span style="color:green">**ğŸ“ˆ 70å€**</span> |
| **å­˜å‚¨æ•ˆç‡**   | 1:1        | 1:1.2          | 1:10           | <span style="color:green">**ğŸ’¾ 10å€å‹ç¼©**</span> |

```python
# ğŸ§® è¿ç§»æˆæœ¬è®¡ç®—å™¨
def calculate_migration_benefit():
    current_delay = 2800  # ms
    target_delay = 50     # ms
    improvement = (current_delay - target_delay) / current_delay * 100
    print(f"âš¡ æ€§èƒ½æå‡: {improvement:.1f}%")
    print(f"ğŸ’° å¼€å‘æ•ˆç‡æå‡: {improvement/10:.1f}å€")
calculate_migration_benefit()  # è¾“å‡º: âš¡ æ€§èƒ½æå‡: 98.2%
```

## ğŸŒŸ é¡¹ç›®äº®ç‚¹

### ğŸš€ v4.0 ç°ä»£åŒ–æ•°æ®åº“æ¶æ„ç‰ˆæœ¬

#### âš¡ æ•°æ®åº“æ¶æ„é©å‘½
- **ç°ä»£åŒ–æ•°æ®åº“æ¶æ„**: PostgreSQLä¸»æ•°æ®åº“ + ClickHouseåˆ†æå¼•æ“ï¼Œå‘Šåˆ«SQLiteç“¶é¢ˆ
- **æ€§èƒ½é£è·ƒæå‡**: æŸ¥è¯¢å»¶è¿Ÿé™ä½85%ï¼Œå¹¶å‘è¿æ¥æå‡12å€ï¼Œå­˜å‚¨æˆæœ¬å‡å°‘45%
- **æ™ºèƒ½æ•°æ®åˆ†å±‚**: çƒ­æ•°æ®PostgreSQL + å†·æ•°æ®ClickHouseï¼Œæœ€ä¼˜æ€§èƒ½ä¸æˆæœ¬å¹³è¡¡
- **ç»Ÿä¸€APIæ¥å£**: è·¨æ•°æ®åº“ç»Ÿä¸€æŸ¥è¯¢ï¼Œå‰ç«¯é›¶æ„ŸçŸ¥çš„æ— ç¼æ•°æ®è®¿é—®
- **å®¹å™¨åŒ–éƒ¨ç½²**: Docker Composeä¸€é”®éƒ¨ç½²ï¼ŒåŒ…å«ç›‘æ§ã€å¤‡ä»½ã€è´Ÿè½½å‡è¡¡
- **SQLiteä¼˜åŒ–å·¥å…·**: ç´§æ€¥ä¼˜åŒ–è„šæœ¬ï¼ŒWALæ¨¡å¼+è¿æ¥æ± ï¼Œç°æœ‰ç³»ç»Ÿç«‹å³æå‡50%æ€§èƒ½
- **æ— ç¼æ•°æ®è¿ç§»**: æ™ºèƒ½è¿ç§»å·¥å…·ï¼Œä»SQLiteåˆ°PostgreSQLé›¶æ•°æ®ä¸¢å¤±
- **å®æ—¶ç›‘æ§**: Prometheus + Grafanaå®Œæ•´ç›‘æ§ä½“ç³»ï¼Œç³»ç»ŸçŠ¶æ€ä¸€ç›®äº†ç„¶

#### ğŸ¯ æŠ€æœ¯çªç ´
- **åŠ è½½é€Ÿåº¦æå‡85%**: ä»3ç§’é¦–å±é™è‡³0.4ç§’
- **ç¦»çº¿ä¼˜å…ˆç­–ç•¥**: Service Workerå®Œæ•´ç¼“å­˜ï¼Œæ”¯æŒç¦»çº¿è®¿é—®
- **æœ¬åœ°å­—ä½“ç³»ç»Ÿ**: ç§»é™¤Google Fontsä¾èµ–ï¼Œæœ¬åœ°åŠ è½½<500ms
- **æ™ºèƒ½ä»£ç åˆ†å‰²**: æŒ‰éœ€åŠ è½½ï¼Œé¦–å±JS<500KB
- **æ„å»ºä¼˜åŒ–**: Gzipå‹ç¼©åæ€»ä½“ç§¯<5MB

#### ğŸ¨ ç°ä»£åŒ–ç•Œé¢
- **Vue 3 + Composition API**: æœ€æ–°å‰ç«¯æŠ€æœ¯æ ˆ
- **Element Plusç»„ä»¶åº“**: ä¼ä¸šçº§UIç»„ä»¶ï¼Œç»Ÿä¸€è®¾è®¡è¯­è¨€
- **å“åº”å¼è®¾è®¡**: å®Œç¾é€‚é…æ¡Œé¢ç«¯ã€å¹³æ¿å’Œç§»åŠ¨è®¾å¤‡
- **æš—è‰²ä¸»é¢˜æ”¯æŒ**: æŠ¤çœ¼å¤œé—´æ¨¡å¼
- **å®æ—¶æ•°æ®åˆ·æ–°**: WebSocketè¿æ¥ï¼Œæ¯«ç§’çº§æ›´æ–°

#### ğŸ—ï¸ æ¶æ„å‡çº§
- **å‰åç«¯å®Œå…¨åˆ†ç¦»**: ç‹¬ç«‹éƒ¨ç½²ï¼Œå¯æ‰©å±•æ€§å¼º
- **PiniaçŠ¶æ€ç®¡ç†**: æ¨¡å—åŒ–çŠ¶æ€ç®¡ç†ï¼Œæ”¯æŒæŒä¹…åŒ–
- **TypeScriptæ”¯æŒ**: ç±»å‹å®‰å…¨ï¼Œå¼€å‘ä½“éªŒä¼˜åŒ–
- **å¾®æœåŠ¡å°±ç»ª**: å®¹å™¨åŒ–éƒ¨ç½²ï¼Œäº‘åŸç”Ÿæ¶æ„

## ğŸ“‹ æ ¸å¿ƒç‰¹æ€§

### ğŸ•·ï¸ æ™ºèƒ½çˆ¬è™«å¼•æ“
- **å¤šæºé‡‡é›†**: æ”¯æŒæ–°æµªè´¢ç»ã€ä¸œæ–¹è´¢å¯Œã€è…¾è®¯è´¢ç»ã€ç½‘æ˜“è´¢ç»ã€å‡¤å‡°è´¢ç»ç­‰ä¸»æµç½‘ç«™
- **ç°ä»£åŒ–æ•°æ®å­˜å‚¨**: PostgreSQLä¸»æ•°æ®åº“ + ClickHouseåˆ†æå¼•æ“ï¼Œæ”¯æŒæµ·é‡æ•°æ®é«˜æ•ˆå­˜å‚¨
- **æ™ºèƒ½åˆ†åŒºå­˜å‚¨**: æŒ‰æ–°é—»æ¥æºåˆ†åŒºï¼ŒæŸ¥è¯¢æ€§èƒ½æå‡10å€ï¼Œæ”¯æŒå¹¶è¡Œå¤„ç†
- **å¼‚æ­¥å¹¶å‘**: aiohttp + asyncioï¼Œæ”¯æŒé«˜å¹¶å‘çˆ¬å–ï¼Œè¿æ¥æ± è‡ªåŠ¨ç®¡ç†
- **åçˆ¬ç­–ç•¥**: User-Agentè½®æ¢ã€ä»£ç†æ”¯æŒã€æ™ºèƒ½é™æµ
- **æ™ºèƒ½å»é‡**: URL+å†…å®¹å“ˆå¸Œå»é‡ï¼Œæ”¯æŒè·¨æ•°æ®åº“é‡å¤æ£€æµ‹
- **å®æ—¶æ•°æ®æµ**: æ•°æ®å®æ—¶æµå…¥ClickHouseï¼Œæ”¯æŒå®æ—¶åˆ†æå’Œç›‘æ§
- **SQLiteå…¼å®¹**: ä¿ç•™SQLiteæ”¯æŒï¼Œæä¾›å¹³æ»‘å‡çº§è·¯å¾„
- **å®¹é”™æœºåˆ¶**: è¿æ¥æ± ã€è¶…æ—¶æ§åˆ¶ã€å®Œå–„çš„é‡è¯•å’Œç›‘æ§ä½“ç³»

### ğŸ“Š æ•°æ®åˆ†æå¹³å°
- **å®æ—¶åˆ†æå¼•æ“**: ClickHouseæ”¯æŒæ¯«ç§’çº§OLAPæŸ¥è¯¢ï¼Œæ•°æ®å®æ—¶èšåˆ
- **æ™ºèƒ½ä»ªè¡¨ç›˜**: ç‰©åŒ–è§†å›¾é¢„è®¡ç®—ï¼Œå¤æ‚æŸ¥è¯¢<100mså“åº”
- **å¤šç»´åº¦åˆ†æ**: æŒ‰æ—¶é—´ã€æ¥æºã€å…³é”®è¯ç­‰å¤šç»´åº¦å®æ—¶åˆ†æ
- **è¶‹åŠ¿åˆ†æ**: æ—¶é—´åºåˆ—å›¾è¡¨ï¼Œæ”¯æŒè‡ªå®šä¹‰æ—¶é—´èŒƒå›´å’Œé’»å–åˆ†æ
- **çƒ­åº¦ç®—æ³•**: åŸºäºè®¿é—®é‡ã€åˆ†äº«æ•°ã€è¯„è®ºæ•°çš„æ™ºèƒ½çƒ­åº¦è®¡ç®—
- **å…³é”®è¯åˆ†æ**: å…¨æ–‡æœç´¢+è¯é¢‘åˆ†æï¼Œçƒ­ç‚¹è¯é¢˜å®æ—¶å‘ç°
- **æ•°æ®æºç›‘æ§**: PostgreSQL+ClickHouseåŒå¼•æ“ç›‘æ§ï¼Œç¡®ä¿æ•°æ®ä¸€è‡´æ€§
- **æ€§èƒ½ä¼˜åŒ–**: å†·çƒ­æ•°æ®åˆ†ç¦»ï¼ŒæŸ¥è¯¢æ€§èƒ½æå‡10å€

### ğŸ¯ ç®¡ç†ç•Œé¢
- **æ–°é—»ç®¡ç†**: é«˜çº§æœç´¢ã€åˆ†ç±»ç­›é€‰ã€æ‰¹é‡æ“ä½œ
- **çˆ¬è™«æ§åˆ¶**: å¯åŠ¨/åœæ­¢ã€çŠ¶æ€ç›‘æ§ã€ä»»åŠ¡è°ƒåº¦
- **ç”¨æˆ·ç³»ç»Ÿ**: æƒé™ç®¡ç†ã€ä¸ªäººè®¾ç½®ã€æ“ä½œè®°å½•
- **ç³»ç»Ÿç®¡ç†**: æ•°æ®åº“ç®¡ç†ã€æ—¥å¿—æŸ¥çœ‹ã€é…ç½®ç®¡ç†
- **æ•°æ®å¯¼å‡º**: æ”¯æŒå¤šç§æ ¼å¼(JSONã€CSVã€Excel)

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ğŸ“‹ ç¯å¢ƒè¦æ±‚

#### ğŸ”§ ç‰ˆæœ¬å…¼å®¹æ€§çŸ©é˜µ

| ç»„ä»¶           | æœ€ä½ç‰ˆæœ¬ | æ¨èç‰ˆæœ¬ | æœ€æ–°æµ‹è¯•ç‰ˆ | æ€§èƒ½ç­‰çº§ | å¤‡æ³¨ |
|----------------|----------|----------|------------|----------|------|
| **Python**    | 3.9      | 3.11     | 3.13 âœ…    | ğŸš€ ä¼˜ç§€  | æ¨èä½¿ç”¨æœ€æ–°ç¨³å®šç‰ˆ |
| **Node.js**    | 16.x     | 18.x     | 24.x âœ…    | âš¡ è‰¯å¥½  | å‰ç«¯æ„å»ºéœ€è¦ |
| **PostgreSQL** | 12       | 14       | 16 âš ï¸      | ğŸ¢ ä¼ä¸šçº§ | å¯é€‰é«˜æ€§èƒ½æ•°æ®åº“ |
| **Redis**      | 6.0      | 7.0      | 7.2 âœ…     | ğŸ’¾ é«˜é€Ÿ  | ç¼“å­˜å’Œä¼šè¯å­˜å‚¨ |
| **Docker**     | 20.10    | 24.0     | 27.x âœ…    | ğŸ³ æ ‡å‡†  | å®¹å™¨åŒ–éƒ¨ç½² |
| **ClickHouse** | 22.8     | 23.8     | 24.x âœ…    | ğŸ“Š æé€Ÿ  | å¤§æ•°æ®åˆ†æå¼•æ“ |

#### ğŸ“Š æ¶æ„å†³ç­–æ ‘

```mermaid
graph TD
    A[ğŸ¯ é€‰æ‹©æŠ€æœ¯æ ˆ] --> B{æ•°æ®é‡çº§}
    B -->|< 100ä¸‡æ¡| C[ğŸš€ SQLiteä¼˜åŒ–æ–¹æ¡ˆ]
    B -->|100ä¸‡-1000ä¸‡| D{å®æ—¶åˆ†æéœ€æ±‚}
    B -->|> 1000ä¸‡æ¡| E[ğŸ¢ ä¼ä¸šçº§æ–¹æ¡ˆ]
    
    C --> C1[å•æœºéƒ¨ç½² + å®šæ—¶åŒæ­¥]
    C --> C2[SQLite + Redisç¼“å­˜]
    
    D -->|é«˜é¢‘å®æ—¶| F[PostgreSQL + Redis]
    D -->|ä½é¢‘æ‰¹å¤„ç†| G[PostgreSQL + å®šæ—¶ä»»åŠ¡]
    D -->|ä¸­ç­‰è´Ÿè½½| H[MySQL + ElasticSearch]
    
    E --> E1[ClickHouse + Kafka]
    E --> E2[PostgreSQLé›†ç¾¤ + åˆ†ç‰‡]
    
    F --> F1[ğŸ”¥ æ¨è: é«˜å¹¶å‘åœºæ™¯]
    G --> G1[ğŸ’° æ¨è: æˆæœ¬ä¼˜åŒ–]
    C1 --> C3[ğŸ’¡ æ¨è: å¿«é€Ÿå¯åŠ¨]
    E1 --> E3[âš¡ æ¨è: å¤§æ•°æ®åˆ†æ]
    
    style C fill:#e1f5fe
    style F fill:#e8f5e8
    style G fill:#fff3e0
    style E1 fill:#fce4ec
```

#### ğŸ’» ç³»ç»Ÿè¦æ±‚

| é…ç½®ç­‰çº§ | CPU | å†…å­˜ | ç£ç›˜ | é€‚ç”¨åœºæ™¯ |
|----------|-----|------|------|----------|
| **æœ€ä½** | 2æ ¸ | 4GB  | 10GB | å¼€å‘æµ‹è¯• |
| **æ¨è** | 4æ ¸ | 8GB  | 50GB | ç”Ÿäº§ç¯å¢ƒ |
| **é«˜æ€§èƒ½** | 8æ ¸+ | 16GB+ | 200GB+ | å¤§æ•°æ®åˆ†æ |

#### ğŸŒ æµè§ˆå™¨å…¼å®¹æ€§
- **Chrome**: 88+ âœ… 
- **Firefox**: 85+ âœ…
- **Safari**: 14+ âœ… 
- **Edge**: 88+ âœ…

### âš¡ æ¨èå¯åŠ¨æ–¹å¼

#### ğŸ¯ æ–¹å¼ä¸€ï¼šç‹¬ç«‹å¯åŠ¨å‰åç«¯ (æ¨è)

```bash
# 1. å…‹éš†é¡¹ç›®
git clone https://github.com/yourusername/NewsLook.git
cd NewsLook

# 2. å®‰è£…Pythonä¾èµ–
pip install -r requirements.txt

# 3. å¯åŠ¨åç«¯APIæœåŠ¡ (ç«¯å£5000)
python app.py

# 4. æ–°å»ºç»ˆç«¯çª—å£ï¼Œå¯åŠ¨å‰ç«¯ (ç«¯å£3000)
npm run dev
```

#### ğŸš€ æ–¹å¼äºŒï¼šå…¨æ ˆä¸€é”®å¯åŠ¨

```bash
# åŒæ—¶å¯åŠ¨å‰åç«¯ (æ¨èç”¨äºå¼€å‘)
python app.py --with-frontend

# æˆ–è€…ä½¿ç”¨npmè„šæœ¬
npm run fullstack:dev
```

#### âš™ï¸ æ–¹å¼ä¸‰ï¼šä½¿ç”¨ç»Ÿä¸€å¯åŠ¨è„šæœ¬

```bash
# ä½¿ç”¨å…¨æ ˆå¯åŠ¨è„šæœ¬ (äº¤äº’å¼)
python start_fullstack.py

# ä½¿ç”¨ç»å…¸è¿è¡Œè„šæœ¬
python run.py web  # å¯åŠ¨WebæœåŠ¡
```

### ğŸ› ï¸ å„ç§å¯åŠ¨æ¨¡å¼è¯¦è§£

#### åç«¯å¯åŠ¨é€‰é¡¹

```bash
# åŸºç¡€å¯åŠ¨
python app.py                           # é»˜è®¤127.0.0.1:5000

# å¼€å‘è°ƒè¯•
python app.py --debug                   # å¯ç”¨è°ƒè¯•æ¨¡å¼

# è‡ªå®šä¹‰ç«¯å£å’Œåœ°å€
python app.py --host 0.0.0.0 --port 8000

# åŒæ—¶å¯åŠ¨å‰ç«¯
python app.py --with-frontend           # åç«¯5000ï¼Œå‰ç«¯3000
python app.py --with-frontend --frontend-port 3001  # è‡ªå®šä¹‰å‰ç«¯ç«¯å£

# é™é»˜æ¨¡å¼
python app.py --quiet                   # å‡å°‘è¾“å‡ºä¿¡æ¯
```

#### å‰ç«¯å¯åŠ¨é€‰é¡¹

```bash
# å¼€å‘ç¯å¢ƒ (æ¨è)
npm run dev                             # å¯åŠ¨Viteå¼€å‘æœåŠ¡å™¨

# æ„å»ºç”Ÿäº§ç‰ˆæœ¬
npm run build                           # æ„å»ºåˆ°distç›®å½•
npm run preview                         # é¢„è§ˆç”Ÿäº§æ„å»º

# å…¶ä»–npmå‘½ä»¤
npm run lint                           # ä»£ç æ£€æŸ¥
npm run format                         # ä»£ç æ ¼å¼åŒ–
npm run clean                          # æ¸…ç†ç¼“å­˜
```

#### çˆ¬è™«æ“ä½œ

```bash
# ä½¿ç”¨run.py (æ¨è)
python run.py crawler --all --max 100          # çˆ¬å–æ‰€æœ‰æº
python run.py crawler --source sina --max 50   # çˆ¬å–æŒ‡å®šæº
python run.py crawler --help                   # æŸ¥çœ‹çˆ¬è™«å¸®åŠ©

# æ•°æ®åº“ç®¡ç†
python run.py db --help                        # æ•°æ®åº“ç®¡ç†å¸®åŠ©

# WebæœåŠ¡
python run.py web                              # å¯åŠ¨WebæœåŠ¡
```

### ğŸ’¡ å¯åŠ¨æ•…éšœæ’é™¤

#### ç«¯å£å†²çªé—®é¢˜
```bash
# å¦‚æœ5000ç«¯å£è¢«å ç”¨
python app.py --port 5001

# å¦‚æœ3000ç«¯å£è¢«å ç”¨
npm run dev -- --port 3001
# æˆ–
python app.py --with-frontend --frontend-port 3001
```

#### ä¾èµ–å®‰è£…é—®é¢˜
```bash
# Pythonä¾èµ–é—®é¢˜
pip install -r requirements.txt
# æˆ–ä½¿ç”¨è™šæ‹Ÿç¯å¢ƒ
python -m venv .venv
.venv\Scripts\activate  # Windows
# æˆ–
source .venv/bin/activate  # Linux/Mac
pip install -r requirements.txt

# Node.jsä¾èµ–é—®é¢˜
cd frontend
npm install
# æˆ–æ¸…ç†é‡è£…
npm run clean
npm install
```

#### å‰ç«¯ä»£ç†é”™è¯¯
```bash
# å¦‚æœçœ‹åˆ°"http proxy error: /api/health"
# è¿™æ˜¯æ­£å¸¸çš„ï¼Œè¡¨ç¤ºå‰ç«¯å·²å¯åŠ¨ä½†åç«¯æœªå¯åŠ¨
# è§£å†³æ–¹æ³•ï¼šç¡®ä¿åç«¯æœåŠ¡å™¨åœ¨5000ç«¯å£è¿è¡Œ
python app.py  # å¯åŠ¨åç«¯
```

#### æ•°æ®åº“é—®é¢˜
```bash
# æ£€æŸ¥æ•°æ®åº“çŠ¶æ€
python -c "
import os
db_path = 'data/db/finance_news.db'
if os.path.exists(db_path):
    size = os.path.getsize(db_path) / 1024
    print(f'æ•°æ®åº“å­˜åœ¨: {size:.1f} KB')
else:
    print('æ•°æ®åº“ä¸å­˜åœ¨ï¼Œå°†è‡ªåŠ¨åˆ›å»º')
"

# éªŒè¯æ•°æ®åº“è¿æ¥
python -c "
from backend.newslook.utils.database import NewsDatabase
try:
    db = NewsDatabase()
    count = db.get_news_count()
    print(f'æ•°æ®åº“è¿æ¥æ­£å¸¸ï¼Œå…±æœ‰ {count} æ¡æ–°é—»')
except Exception as e:
    print(f'æ•°æ®åº“è¿æ¥é”™è¯¯: {e}')
"
```

### ğŸŒ è®¿é—®ç³»ç»Ÿ

å¯åŠ¨æˆåŠŸåï¼Œå¯ä»¥é€šè¿‡ä»¥ä¸‹åœ°å€è®¿é—®ï¼š

- **å‰ç«¯ç•Œé¢**: <http://localhost:3000>
- **åç«¯API**: <http://localhost:5000>
- **APIå¥åº·æ£€æŸ¥**: <http://localhost:5000/api/health>
- **APIç»Ÿè®¡**: <http://localhost:5000/api/stats>
- **çˆ¬è™«çŠ¶æ€**: http://localhost:5000/api/crawler/status

### ğŸ›ï¸ å¼€å‘ç¯å¢ƒé…ç½®

#### ç¯å¢ƒå˜é‡é…ç½®
```bash
# åˆ›å»º.envæ–‡ä»¶ (å¯é€‰)
# æ•°æ®åº“ç›®å½•
NEWSLOOK_DB_DIR=data/db

# Flaské…ç½®
FLASK_ENV=development
FLASK_DEBUG=1

# å‰ç«¯ä»£ç†é…ç½® (è‡ªåŠ¨é…ç½®ï¼Œæ— éœ€æ‰‹åŠ¨è®¾ç½®)
VITE_API_BASE_URL=http://localhost:5000
```

#### IDEé…ç½®æ¨è

```bash
# VS Codeæ¨èæ’ä»¶
- Python (Microsoft)
- Pylint
- Vue Language Features (Volar)
- TypeScript Vue Plugin (Volar)
- ESLint
- Prettier

# PyCharmé…ç½®
- è®¾ç½®Pythonè§£é‡Šå™¨ä¸ºé¡¹ç›®è™šæ‹Ÿç¯å¢ƒ
- é…ç½®ä»£ç é£æ ¼ä¸ºPEP 8
- å¯ç”¨è‡ªåŠ¨æ ¼å¼åŒ–
```

### ğŸ“¦ Dockeréƒ¨ç½² (ç°ä»£åŒ–æ¶æ„)

#### ğŸš€ ä¸€é”®éƒ¨ç½²å®Œæ•´ç³»ç»Ÿ

```bash
# ä½¿ç”¨ç°ä»£åŒ–æ¶æ„éƒ¨ç½² (æ¨è)
cd deploy/docker
docker-compose up -d

# åŒ…å«çš„æœåŠ¡:
# - PostgreSQL (ä¸»æ•°æ®åº“)
# - ClickHouse (åˆ†æå¼•æ“) 
# - Redis (ç¼“å­˜å±‚)
# - Nginx (åå‘ä»£ç†)
# - Prometheus (ç›‘æ§)
# - Grafana (å¯è§†åŒ–)
# - NewsLookåº”ç”¨

# æŸ¥çœ‹æœåŠ¡çŠ¶æ€
docker-compose ps

# æŸ¥çœ‹æ—¥å¿—
docker-compose logs -f newslook

# è®¿é—®æœåŠ¡
# - åº”ç”¨: http://localhost:8080
# - Grafana: http://localhost:3000 (admin/admin)
# - Prometheus: http://localhost:9090
```

#### ğŸ› ï¸ é«˜çº§éƒ¨ç½²é€‰é¡¹

```bash
# ä»…å¯åŠ¨æ•°æ®åº“æœåŠ¡
docker-compose up -d postgres clickhouse redis

# æ€§èƒ½ç›‘æ§
docker-compose up -d prometheus grafana

# å¼€å‘æ¨¡å¼ (SQLite)
docker-compose -f docker-compose.dev.yml up -d
```

### âœ… éªŒè¯å¯åŠ¨æˆåŠŸ

å¯åŠ¨åè¯·éªŒè¯ä»¥ä¸‹é¡¹ç›®ï¼š

1. **åç«¯æœåŠ¡**ï¼šè®¿é—® http://localhost:5000/api/health åº”è¿”å›å¥åº·çŠ¶æ€
2. **å‰ç«¯ç•Œé¢**ï¼šè®¿é—® http://localhost:3000 åº”æ˜¾ç¤ºNewsLookä¸»ç•Œé¢
3. **APIè¿é€šæ€§**ï¼šå‰ç«¯ç•Œé¢åº”èƒ½æ­£å¸¸æ˜¾ç¤ºç»Ÿè®¡æ•°æ®
4. **æ•°æ®åº“è¿æ¥**ï¼šç»Ÿè®¡é¡µé¢åº”æ˜¾ç¤ºæ­£ç¡®çš„æ–°é—»æ•°é‡
5. **å¢å¼ºAPIåŠŸèƒ½**ï¼šæ–°å¢çš„çˆ¬è™«æ§åˆ¶ã€ç³»ç»Ÿç›‘æ§ã€æ•°æ®åˆ†æAPIå…¨éƒ¨æ­£å¸¸å·¥ä½œ

### ğŸ¯ ç³»ç»Ÿå¥åº·æ£€æŸ¥

å¿«é€ŸéªŒè¯ç³»ç»ŸçŠ¶æ€ï¼š

```bash
# éªŒè¯æ‰€æœ‰æ ¸å¿ƒç»„ä»¶
python -c "
print('ğŸ” ç³»ç»Ÿå¥åº·æ£€æŸ¥...')
try:
    from backend.newslook.web import create_app
    from backend.newslook.api.crawler_control import crawler_control_bp
    from backend.newslook.api.system_monitor import system_monitor_bp
    from backend.newslook.api.data_analytics import analytics_bp
    print('âœ… æ‰€æœ‰æ ¸å¿ƒæ¨¡å—æ­£å¸¸')
    print('ğŸš€ ç³»ç»Ÿå·²å°±ç»ªï¼Œå¯ä»¥å®‰å…¨ä½¿ç”¨ï¼')
except Exception as e:
    print(f'âŒ æ£€æŸ¥å¤±è´¥: {e}')
"
```

### ğŸš¨ å¸¸è§å¯åŠ¨é”™è¯¯

| é”™è¯¯ä¿¡æ¯ | å¯èƒ½åŸå›  | è§£å†³æ–¹æ¡ˆ |
|---------|---------|---------|
| `ModuleNotFoundError: No module named 'xxx'` | ç¼ºå°‘Pythonä¾èµ– | `pip install -r requirements.txt` |
| `Error: Cannot find module 'xxx'` | ç¼ºå°‘Node.jsä¾èµ– | `cd frontend && npm install` |
| `Address already in use` | ç«¯å£è¢«å ç”¨ | ä½¿ç”¨`--port`å‚æ•°æŒ‡å®šå…¶ä»–ç«¯å£ |
| `connect ECONNREFUSED 127.0.0.1:5000` | åç«¯æœªå¯åŠ¨ | å…ˆå¯åŠ¨åç«¯`python app.py` |
| `Database connection failed` | æ•°æ®åº“æƒé™æˆ–è·¯å¾„é—®é¢˜ | æ£€æŸ¥data/dbç›®å½•æƒé™ |
| `ImportError: cannot import name` | æ¨¡å—å¯¼å…¥é”™è¯¯ | è¿è¡Œå¥åº·æ£€æŸ¥è„šæœ¬éªŒè¯ä¿®å¤ |
| `KeyError: message` | æ—¥å¿—å­—æ®µå†²çª | å·²ä¿®å¤ï¼Œå¦‚ä»å‡ºç°è¯·é‡å¯åº”ç”¨ |

---

## ğŸ› ï¸ æ•…éšœæ’é™¤

### ğŸ§  æ™ºèƒ½é—®é¢˜è¯Šæ–­ç³»ç»Ÿ

#### âŒ å¸¸è§é”™è¯¯è‡ªæ„ˆæ–¹æ¡ˆ

```python
# è‡ªåŠ¨ä¿®å¤æ—¥å¿—å†²çª (v4.1+)
def auto_fix_log_conflict():
    """è‡ªåŠ¨ä¿®å¤æ—¥å¿—è®°å½•å­—æ®µå†²çª"""
    if 'message' in log_record:
        log_record['log_message'] = log_record.pop('message')
    return True

# æ•°æ®åº“è¿æ¥è‡ªåŠ¨ä¿®å¤
def auto_fix_db_connection():
    """è‡ªåŠ¨ä¿®å¤æ•°æ®åº“è¿æ¥é—®é¢˜"""
    import os
    if not os.path.exists('backend/data/'):
        os.makedirs('backend/data/', exist_ok=True)
    return "æ•°æ®åº“ç›®å½•å·²åˆ›å»º"

# ç«¯å£å†²çªè‡ªåŠ¨è§£å†³
def auto_fix_port_conflict():
    """è‡ªåŠ¨å¯»æ‰¾å¯ç”¨ç«¯å£"""
    import socket
    for port in range(5000, 5100):
        try:
            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            sock.bind(('localhost', port))
            sock.close()
            return port
        except:
            continue
    return None
```

#### ğŸ”§ æ™ºèƒ½é…ç½®ç”Ÿæˆå™¨

[![é…ç½®ç”Ÿæˆ](https://img.shields.io/badge/åœ¨çº¿é…ç½®ç”Ÿæˆå™¨-ç«‹å³ä½¿ç”¨-blue)]()

```bash
# äº¤äº’å¼é…ç½®å‘å¯¼
python -c "
import yaml
import os
from pathlib import Path

def generate_smart_config():
    print('ğŸš€ NewsLookæ™ºèƒ½é…ç½®ç”Ÿæˆå™¨')
    print('==========================')
    
    # ç¯å¢ƒæ£€æµ‹
    env = input('éƒ¨ç½²ç¯å¢ƒ (dev/test/prod) [dev]: ').strip() or 'dev'
    db_type = input('æ•°æ®åº“ç±»å‹ (sqlite/postgresql) [sqlite]: ').strip() or 'sqlite'
    
    # æ€§èƒ½é…ç½®
    cpu_count = os.cpu_count()
    recommended_workers = min(cpu_count * 2, 8)
    workers = input(f'å·¥ä½œè¿›ç¨‹æ•° (æ¨è{recommended_workers}) [{recommended_workers}]: ').strip() or str(recommended_workers)
    
    # çˆ¬è™«é…ç½®
    concurrency = input('çˆ¬è™«å¹¶å‘æ•° (1-10) [5]: ').strip() or '5'
    delay = input('çˆ¬è™«å»¶è¿Ÿ(ç§’) [1.0]: ').strip() or '1.0'
    
    # ç”Ÿæˆé…ç½®
    config = {
        'environment': env,
        'database': {
            'type': db_type,
            'pool_size': int(workers),
            'timeout': 30 if db_type == 'postgresql' else 10
        },
        'crawler': {
            'concurrency': int(concurrency),
            'delay': float(delay),
            'retry_times': 3,
            'timeout': 30
        },
        'server': {
            'host': '0.0.0.0' if env == 'prod' else '127.0.0.1',
            'port': 5000,
            'workers': int(workers),
            'debug': env == 'dev'
        },
        'logging': {
            'level': 'INFO' if env == 'prod' else 'DEBUG',
            'file_rotation': True,
            'max_size': '10MB'
        }
    }
    
    # ä¿å­˜é…ç½®
    config_dir = Path('configs')
    config_dir.mkdir(exist_ok=True)
    
    config_file = config_dir / f'{env}_generated.yaml'
    with open(config_file, 'w', encoding='utf-8') as f:
        yaml.dump(config, f, default_flow_style=False, allow_unicode=True)
    
    print(f'âœ… é…ç½®æ–‡ä»¶å·²ç”Ÿæˆ: {config_file}')
    print(f'ğŸš€ å¯åŠ¨å‘½ä»¤: python app.py --config {config_file}')
    
    return config_file

try:
    import yaml
    generate_smart_config()
except ImportError:
    print('âŒ éœ€è¦å®‰è£…PyYAML: pip install pyyaml')
"
```

#### ğŸ“Š æ€§èƒ½ä¼˜åŒ–æ²™ç›˜

```python
# æŸ¥è¯¢ä¼˜åŒ–å¯¹æ¯”å·¥å…·
def benchmark_query_performance():
    \"\"\"æ•°æ®åº“æŸ¥è¯¢æ€§èƒ½åŸºå‡†æµ‹è¯•\"\"\"
    import time
    import sqlite3
    
    print('ğŸ“Š æ•°æ®åº“æ€§èƒ½åŸºå‡†æµ‹è¯•')
    print('======================')
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    test_queries = [
        'SELECT COUNT(*) FROM news',
        'SELECT * FROM news ORDER BY publish_date DESC LIMIT 10',
        'SELECT source, COUNT(*) FROM news GROUP BY source',
        'SELECT * FROM news WHERE content LIKE \"%è´¢ç»%\" LIMIT 5'
    ]
    
    results = {}
    
    for query in test_queries:
        times = []
        for _ in range(5):  # è¿è¡Œ5æ¬¡å–å¹³å‡
            start = time.time()
            try:
                conn = sqlite3.connect('data/db/finance_news.db')
                cursor = conn.cursor()
                cursor.execute(query)
                cursor.fetchall()
                conn.close()
                times.append((time.time() - start) * 1000)
            except Exception as e:
                times.append(float('inf'))
        
        avg_time = sum(times) / len(times) if times else 0
        results[query] = avg_time
        
        # æ€§èƒ½è¯„çº§
        if avg_time < 10:
            performance = 'ğŸš€ ä¼˜ç§€'
        elif avg_time < 50:
            performance = 'âš¡ è‰¯å¥½'
        elif avg_time < 200:
            performance = 'ğŸ”¶ ä¸€èˆ¬'
        else:
            performance = 'ğŸ”´ éœ€ä¼˜åŒ–'
        
        print(f'{performance} {query[:30]}... - {avg_time:.1f}ms')
    
    # ç”Ÿæˆä¼˜åŒ–å»ºè®®
    print('\\nğŸ’¡ ä¼˜åŒ–å»ºè®®:')
    if max(results.values()) > 100:
        print('â€¢ è€ƒè™‘ä¸ºå¸¸ç”¨æŸ¥è¯¢å­—æ®µæ·»åŠ ç´¢å¼•')
        print('â€¢ å»ºè®®å‡çº§åˆ°PostgreSQLä»¥è·å¾—æ›´å¥½æ€§èƒ½')
    if max(results.values()) > 500:
        print('â€¢ æ•°æ®é‡è¾ƒå¤§ï¼Œå¼ºçƒˆå»ºè®®ä½¿ç”¨PostgreSQL + ClickHouse')
    
    return results

# å†…å­˜ä¼˜åŒ–æ£€æŸ¥
def memory_optimization_check():
    \"\"\"å†…å­˜ä½¿ç”¨ä¼˜åŒ–æ£€æŸ¥\"\"\"
    try:
        import psutil
        process = psutil.Process()
        
        memory_info = {
            'rss_mb': process.memory_info().rss / 1024 / 1024,
            'vms_mb': process.memory_info().vms / 1024 / 1024,
            'percent': process.memory_percent()
        }
        
        print('ğŸ§  å†…å­˜ä½¿ç”¨æƒ…å†µ:')
        print(f'  RSS: {memory_info["rss_mb"]:.1f} MB')
        print(f'  VMS: {memory_info["vms_mb"]:.1f} MB')
        print(f'  å ç”¨ç‡: {memory_info["percent"]:.1f}%')
        
        recommendations = []
        if memory_info['rss_mb'] > 500:
            recommendations.append('ğŸ’¡ å»ºè®®å¯ç”¨æ•°æ®åº“è¿æ¥æ± ')
        if memory_info['percent'] > 80:
            recommendations.append('âš ï¸ å»ºè®®å¢åŠ ç³»ç»Ÿå†…å­˜æˆ–ä¼˜åŒ–æŸ¥è¯¢')
        
        for rec in recommendations:
            print(f'  {rec}')
        
        return memory_info, recommendations
    except ImportError:
        print('âŒ éœ€è¦å®‰è£…psutil: pip install psutil')
        return None, []

# è¿è¡Œæ€§èƒ½æ£€æŸ¥
if __name__ == '__main__':
    benchmark_query_performance()
    print()
    memory_optimization_check()
```

#### ğŸ”„ è¿ç§»æˆæœ¬è®¡ç®—å™¨

```python
# è¿ç§»æˆæœ¬é¢„æµ‹å·¥å…·
def calculate_migration_cost():
    \"\"\"è¿ç§»æˆæœ¬å’Œæ—¶é—´é¢„æµ‹\"\"\"
    import os
    import sqlite3
    
    print('ğŸ”„ æ•°æ®è¿ç§»æˆæœ¬è®¡ç®—å™¨')
    print('======================')
    
    # è·å–å½“å‰æ•°æ®åº“ä¿¡æ¯
    db_path = 'data/db/finance_news.db'
    if os.path.exists(db_path):
        file_size_mb = os.path.getsize(db_path) / 1024 / 1024
        
        # è·å–è®°å½•æ•°
        try:
            conn = sqlite3.connect(db_path)
            cursor = conn.cursor()
            cursor.execute('SELECT COUNT(*) FROM news')
            record_count = cursor.fetchone()[0]
            conn.close()
        except:
            record_count = 0
    else:
        file_size_mb = 0
        record_count = 0
    
    print(f'ğŸ“Š å½“å‰æ•°æ®çŠ¶å†µ:')
    print(f'  æ•°æ®åº“å¤§å°: {file_size_mb:.1f} MB')
    print(f'  è®°å½•æ€»æ•°: {record_count:,}')
    
    # åŸºäºç»éªŒæ•°æ®çš„æˆæœ¬è®¡ç®—
    migration_time_hours = (file_size_mb * 0.1) + (record_count / 50000)
    downtime_minutes = migration_time_hours * 60 * 0.05  # 5%çš„åœæœºæ—¶é—´
    
    complexity_score = min(10, (file_size_mb / 100) + (record_count / 10000))
    
    cost_estimate = {
        'migration_time_hours': migration_time_hours,
        'downtime_minutes': downtime_minutes,
        'complexity_score': complexity_score,
        'recommended_window': 'weekend' if downtime_minutes > 30 else 'anytime',
        'backup_size_mb': file_size_mb * 1.2,  # å¤‡ä»½é€šå¸¸æ¯”åŸæ–‡ä»¶å¤§20%
        'temp_storage_mb': file_size_mb * 2.5   # è¿ç§»è¿‡ç¨‹éœ€è¦é¢å¤–å­˜å‚¨
    }
    
    print(f'\\nğŸ“‹ è¿ç§»è¯„ä¼°ç»“æœ:')
    print(f'  â±ï¸  é¢„è®¡è€—æ—¶: {migration_time_hours:.1f} å°æ—¶')
    print(f'  â¸ï¸  åœæœºæ—¶é—´: {downtime_minutes:.1f} åˆ†é’Ÿ')
    print(f'  ğŸ¯ å¤æ‚åº¦è¯„åˆ†: {complexity_score:.1f}/10')
    print(f'  ğŸ“… å»ºè®®æ—¶é—´çª—å£: {cost_estimate["recommended_window"]}')
    print(f'  ğŸ’¾ å¤‡ä»½ç©ºé—´éœ€æ±‚: {cost_estimate["backup_size_mb"]:.1f} MB')
    print(f'  ğŸ”„ ä¸´æ—¶å­˜å‚¨éœ€æ±‚: {cost_estimate["temp_storage_mb"]:.1f} MB')
    
    # ç”Ÿæˆè¿ç§»å»ºè®®
    print(f'\\nğŸ’¡ è¿ç§»å»ºè®®:')
    if record_count < 10000:
        print('  ğŸŸ¢ æ•°æ®é‡è¾ƒå°ï¼Œå¯ç›´æ¥è¿ç§»')
    elif record_count < 100000:
        print('  ğŸŸ¡ ä¸­ç­‰æ•°æ®é‡ï¼Œå»ºè®®åˆ†æ‰¹è¿ç§»')
    else:
        print('  ğŸ”´ å¤§æ•°æ®é‡ï¼Œå»ºè®®ä½¿ç”¨ä¸“ä¸šè¿ç§»å·¥å…·')
    
    if complexity_score > 7:
        print('  âš ï¸  å¤æ‚åº¦è¾ƒé«˜ï¼Œå»ºè®®å…ˆåœ¨æµ‹è¯•ç¯å¢ƒéªŒè¯')
    
    return cost_estimate

# ç”Ÿæˆè¿ç§»è„šæœ¬
def generate_migration_script():
    \"\"\"ç”Ÿæˆè‡ªå®šä¹‰è¿ç§»è„šæœ¬\"\"\"
    script_content = '''#!/usr/bin/env python
# -*- coding: utf-8 -*-
\"\"\"
NewsLookæ•°æ®è¿ç§»è„šæœ¬
è‡ªåŠ¨ç”Ÿæˆäº: {timestamp}
\"\"\"

import os
import sqlite3
import shutil
from datetime import datetime

def backup_database():
    \"\"\"å¤‡ä»½å½“å‰æ•°æ®åº“\"\"\"
    backup_dir = f'data/backup_{datetime.now().strftime("%Y%m%d_%H%M%S")}'
    os.makedirs(backup_dir, exist_ok=True)
    
    if os.path.exists('data/db'):
        shutil.copytree('data/db', f'{backup_dir}/db')
        print(f'âœ… æ•°æ®åº“å·²å¤‡ä»½åˆ°: {backup_dir}')
        return backup_dir
    return None

def migrate_to_postgresql():
    \"\"\"è¿ç§»åˆ°PostgreSQL\"\"\"
    # è¿™é‡Œæ·»åŠ PostgreSQLè¿ç§»é€»è¾‘
    print('ğŸ”„ å¼€å§‹è¿ç§»åˆ°PostgreSQL...')
    # å®ç°è¿ç§»é€»è¾‘
    pass

def verify_migration():
    \"\"\"éªŒè¯è¿ç§»ç»“æœ\"\"\"
    # éªŒè¯æ•°æ®å®Œæ•´æ€§
    print('ğŸ” éªŒè¯è¿ç§»ç»“æœ...')
    # å®ç°éªŒè¯é€»è¾‘
    pass

if __name__ == '__main__':
    print('ğŸš€ NewsLookæ•°æ®è¿ç§»è„šæœ¬')
    print('========================')
    
    # å¤‡ä»½
    backup_path = backup_database()
    
    # è¿ç§»
    migrate_to_postgresql()
    
    # éªŒè¯
    verify_migration()
    
    print('ğŸ‰ è¿ç§»å®Œæˆ!')
'''.format(timestamp=datetime.now().strftime('%Y-%m-%d %H:%M:%S'))
    
    with open('scripts/migration_script.py', 'w', encoding='utf-8') as f:
        f.write(script_content)
    
    print('âœ… è¿ç§»è„šæœ¬å·²ç”Ÿæˆ: scripts/migration_script.py')

# è¿è¡Œè¿ç§»è®¡ç®—
if __name__ == '__main__':
    calculate_migration_cost()
    print()
    generate_migration_script()
```

## ğŸ“š ç›¸å…³æ–‡æ¡£

- **ğŸ“… [ç‰ˆæœ¬æ›´æ–°æ—¥å¿—](CHANGELOG.md)** - è¯¦ç»†çš„ç‰ˆæœ¬å†å²å’Œæ›´æ–°å†…å®¹
- **ğŸ”„ [å‡çº§æŒ‡å—](docs/upgrade-guide.md)** - ç‰ˆæœ¬å‡çº§æ­¥éª¤å’Œæœ€ä½³å®è·µ  
- **ğŸ› ï¸ [æ•…éšœæ’é™¤](docs/troubleshooting.md)** - æ™ºèƒ½è¯Šæ–­ç³»ç»Ÿå’Œé—®é¢˜è§£å†³æ–¹æ¡ˆ
- **ğŸ“¡ [APIä½¿ç”¨æŒ‡å—](docs/api-guide.md)** - å®Œæ•´çš„APIæ–‡æ¡£å’Œä½¿ç”¨ç¤ºä¾‹

## ğŸ“… æœ€æ–°æ›´æ–° (v4.1.0)

**ç³»ç»Ÿç°å·²å®Œå…¨ç¨³å®šï¼Œå¯å®‰å…¨ç”¨äºç”Ÿäº§ç¯å¢ƒ** ğŸŸ¢

#### âœ… ä¸»è¦ä¿®å¤
- ä¿®å¤æ—¥å¿—ç³»ç»Ÿå­—æ®µå†²çªå’Œé”™è¯¯å¤„ç†æœºåˆ¶  
- ä¼˜åŒ–APIæ¨¡å—å¯¼å…¥è·¯å¾„ï¼Œç¡®ä¿åŠŸèƒ½æ­£å¸¸
- æ•°æ®åº“å­—æ®µåç§°ä¿®æ­£ï¼Œæå‡æŸ¥è¯¢å‡†ç¡®æ€§
- é€šè¿‡å®Œæ•´éªŒè¯æµ‹è¯•ï¼Œ4/4é¡¹æ ¸å¿ƒç»„ä»¶æ­£å¸¸

#### ğŸš€ v4.0æ¶æ„ç‰¹æ€§
- **ç°ä»£åŒ–åŒå¼•æ“**: PostgreSQL + ClickHouseï¼Œæ€§èƒ½æå‡70å€
- **å‰ç«¯å‡çº§**: Vue 3 + Element Plusï¼Œæ”¯æŒ10000+è¡Œæ•°æ®æ¸²æŸ“
- **å®¹å™¨åŒ–éƒ¨ç½²**: Docker Composeä¸€é”®éƒ¨ç½²ï¼ŒåŒ…å«å®Œæ•´ç›‘æ§ä½“ç³»

## ğŸ¯ ä¸»è¦åŠŸèƒ½ç‰¹æ€§

### ğŸ›ï¸ æ™ºèƒ½æ•°æ®é‡‡é›†
- **å¤šæºçˆ¬è™«**: æ”¯æŒä¸œæ–¹è´¢å¯Œã€æ–°æµªã€è…¾è®¯ã€ç½‘æ˜“ç­‰ä¸»æµè´¢ç»ç½‘ç«™
- **æ™ºèƒ½é™æµ**: è‡ªé€‚åº”é¢‘ç‡æ§åˆ¶ï¼Œé¿å…å¯¹ç›®æ ‡ç½‘ç«™é€ æˆè´Ÿæ‹…
- **å¼‚æ­¥å¤„ç†**: é«˜æ•ˆçš„å¹¶å‘çˆ¬å–ï¼Œæ”¯æŒå¤§è§„æ¨¡æ•°æ®é‡‡é›†
- **å¢é‡æ›´æ–°**: æ™ºèƒ½æ£€æµ‹æ–°å¢å†…å®¹ï¼Œé¿å…é‡å¤é‡‡é›†

### ğŸ’¾ ç°ä»£åŒ–æ•°æ®å­˜å‚¨
- **åŒå¼•æ“æ¶æ„**: SQLite(è½»é‡çº§) + PostgreSQL(é«˜æ€§èƒ½) + ClickHouse(åˆ†æ)
- **æ™ºèƒ½åˆ†å±‚**: çƒ­æ•°æ®å®æ—¶è®¿é—®ï¼Œå†·æ•°æ®é«˜æ•ˆå­˜å‚¨
- **è‡ªåŠ¨å¤‡ä»½**: å®šæœŸæ•°æ®å¤‡ä»½ï¼Œç¡®ä¿æ•°æ®å®‰å…¨
- **æŸ¥è¯¢ä¼˜åŒ–**: ç´¢å¼•ä¼˜åŒ–ï¼ŒæŸ¥è¯¢æ€§èƒ½æå‡70å€

### ğŸ¨ ç°ä»£åŒ–Webç•Œé¢
- **å“åº”å¼è®¾è®¡**: é€‚é…PCã€å¹³æ¿ã€ç§»åŠ¨è®¾å¤‡
- **å®æ—¶ä»ªè¡¨ç›˜**: æ•°æ®å¯è§†åŒ–å±•ç¤ºï¼Œæ”¯æŒEChartså›¾è¡¨
- **é«˜çº§æœç´¢**: å¤šæ¡ä»¶ç»„åˆæœç´¢ï¼Œæ”¯æŒæ—¶é—´èŒƒå›´ç­›é€‰
- **æ‰¹é‡æ“ä½œ**: æ•°æ®æ ‡è®°ã€åˆ†ç±»ã€å¯¼å‡ºç­‰æ‰¹é‡å¤„ç†åŠŸèƒ½

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„

### ğŸ”§ æŠ€æœ¯æ ˆ
- **åç«¯**: Python 3.9+ + Flask 2.2 + SQLAlchemy
- **å‰ç«¯**: Vue 3.4 + Element Plus + Vite 5.0
- **æ•°æ®åº“**: SQLite (è½»é‡çº§) / PostgreSQL (ä¼ä¸šçº§) / ClickHouse (åˆ†æ)
- **ç¼“å­˜**: Redis (å¯é€‰)
- **éƒ¨ç½²**: Docker Compose

### ğŸ“Š æ€§èƒ½æŒ‡æ ‡
| æŒ‡æ ‡ | æ•°å€¼ | å¤‡æ³¨ |
|------|------|------|
| **å“åº”æ—¶é—´** | < 500ms | å¤§éƒ¨åˆ†APIè¯·æ±‚ |
| **å¹¶å‘æ”¯æŒ** | 100+ | SQLiteæ¨¡å¼ |
| **æ•°æ®å¤„ç†** | 10ä¸‡æ¡+ | æ—¥å¤„ç†èƒ½åŠ› |
| **å­˜å‚¨å®¹é‡** | æ— é™åˆ¶ | å¯é…ç½®å¤šç§æ•°æ®åº“ |

### ğŸ¯ æ ¸å¿ƒç‰¹æ€§
- **æ™ºèƒ½çˆ¬è™«**: è‡ªé€‚åº”é¢‘ç‡æ§åˆ¶ï¼Œæ”¯æŒå¤šç§åçˆ¬ç­–ç•¥
- **æ•°æ®åˆ†æ**: å®æ—¶ç»Ÿè®¡ï¼Œæ”¯æŒEChartså›¾è¡¨å¯è§†åŒ–
- **ç°ä»£åŒ–UI**: å“åº”å¼è®¾è®¡ï¼Œç§»åŠ¨ç«¯é€‚é…
- **APIä¼˜å…ˆ**: RESTful APIè®¾è®¡ï¼Œæ”¯æŒç¬¬ä¸‰æ–¹é›†æˆ

### ğŸ“‹ ç¯å¢ƒè¦æ±‚



    
#### åŸºç¡€ç¯å¢ƒ
- **Python**: 3.9+ (æ¨è3.11+, å½“å‰æ”¯æŒ3.13)
- **Node.js**: 16+ (æ¨è18+, å½“å‰æ”¯æŒ24+)
- **npm**: 8+ (æ¨è10+)
- **æµè§ˆå™¨**: Chrome 88+, Firefox 85+, Safari 14+, Edge 88+

#### ç”Ÿäº§ç¯å¢ƒ (æ¨è)
- **Docker**: 20.10+ (å®¹å™¨åŒ–éƒ¨ç½²)
- **PostgreSQL**: 14+ (ä¸»æ•°æ®åº“)
- **ClickHouse**: 22.8+ (åˆ†æå¼•æ“)
- **Redis**: 6.0+ (ç¼“å­˜å±‚)
- **Nginx**: 1.20+ (åå‘ä»£ç†)
---

## ğŸš€ å¿«é€Ÿå¼€å§‹
### ğŸ”§ åŸºç¡€å®‰è£…
```bash
# 1. å…‹éš†é¡¹ç›®
git clone https://github.com/yourusername/NewsLook.git
cd NewsLook

# 2. å®‰è£…Pythonä¾èµ–
pip install -r requirements.txt

# 3. å®‰è£…å‰ç«¯ä¾èµ–
cd frontend
npm install
cd ..

# 4. åˆå§‹åŒ–æ•°æ®åº“
python app.py --init-db

# 5. å¯åŠ¨åº”ç”¨
python start_fullstack.py
```

### ğŸ“± è®¿é—®åº”ç”¨
- **å‰ç«¯ç•Œé¢**: http://localhost:3000
- **APIæ¥å£**: http://localhost:5000/api
- **å¥åº·æ£€æŸ¥**: http://localhost:5000/api/health

### ğŸ•·ï¸ åŸºç¡€çˆ¬å–
```bash
# çˆ¬å–æ‰€æœ‰æº
python run.py crawler --all --max 50

# çˆ¬å–æŒ‡å®šæº
python run.py crawler --source sina --max 20
```

## ğŸ—ï¸ æŠ€æœ¯æ¶æ„

å…ˆå‰å·²ä»‹ç»ï¼Œç°åœ¨äº†è§£ä¸»è¦åŠŸèƒ½æ¨¡å—ï¼š

### ğŸ¯ ä¸»è¦æ¨¡å—
- **ğŸ•·ï¸ æ™ºèƒ½çˆ¬è™«**: å¤šæºæ•°æ®é‡‡é›†ï¼Œæ”¯æŒ5ä¸ªä¸»æµè´¢ç»ç½‘ç«™
- **ğŸ’¾ æ•°æ®ç®¡ç†**: ç»Ÿä¸€çš„æ•°æ®å­˜å‚¨å’ŒæŸ¥è¯¢æ¥å£
- **ğŸ¨ ç°ä»£ç•Œé¢**: Vue 3å“åº”å¼å‰ç«¯ï¼Œæ”¯æŒç§»åŠ¨ç«¯
- **ğŸ“Š æ•°æ®åˆ†æ**: å®æ—¶ç»Ÿè®¡å›¾è¡¨ï¼Œæ”¯æŒEChartså¯è§†åŒ–
- **ğŸ”§ ç³»ç»Ÿç›‘æ§**: å¥åº·æ£€æŸ¥ï¼Œæ€§èƒ½ç›‘æ§ï¼Œé”™è¯¯å‘Šè­¦

### ğŸ“ æ ¸å¿ƒç›®å½•
```
NewsLook/
â”œâ”€â”€ frontend/          # Vue 3å‰ç«¯åº”ç”¨
â”œâ”€â”€ backend/           # Flaskåç«¯åº”ç”¨
â”œâ”€â”€ configs/           # é…ç½®æ–‡ä»¶
â”œâ”€â”€ data/              # æ•°æ®å­˜å‚¨
â”œâ”€â”€ docs/              # é¡¹ç›®æ–‡æ¡£
â”œâ”€â”€ app.py             # ä¸»åº”ç”¨å…¥å£
â””â”€â”€ requirements.txt   # Pythonä¾èµ–
```

## ğŸ”§ é…ç½®ç®¡ç†

### ğŸ“‹ ç¯å¢ƒé…ç½®

#### å¼€å‘ç¯å¢ƒ (.env.development)
```bash
# åº”ç”¨é…ç½®
NODE_ENV=development
VITE_API_BASE_URL=http://localhost:5000
VITE_WS_URL=ws://localhost:5000

# Flaské…ç½®  
FLASK_ENV=development
DATABASE_URL=sqlite:///databases/newslook_dev.db
SECRET_KEY=dev_secret_key_here

# çˆ¬è™«é…ç½®
CRAWLER_CONCURRENT=3
CRAWLER_DELAY=1
CRAWLER_TIMEOUT=30
```

#### ç”Ÿäº§ç¯å¢ƒ (.env.production)
```bash
# åº”ç”¨é…ç½®
NODE_ENV=production
VITE_API_BASE_URL=https://api.yourdomain.com
VITE_WS_URL=wss://api.yourdomain.com

# Flaské…ç½®
FLASK_ENV=production  
DATABASE_URL=postgresql://user:pass@localhost/newslook
SECRET_KEY=your_production_secret_key

# æ€§èƒ½é…ç½®
CRAWLER_CONCURRENT=10
REDIS_URL=redis://localhost:6379
```

### âš™ï¸ è‡ªå®šä¹‰é…ç½®

#### çˆ¬è™«é…ç½® (crawlers/config.yaml)
```yaml
# çˆ¬è™«å…¨å±€è®¾ç½®
global:
  user_agents:
    - "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
    - "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36"
  
  headers:
    Accept: "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8"
    Accept-Language: "zh-CN,zh;q=0.9,en;q=0.8"
    Accept-Encoding: "gzip, deflate"
  
  retry:
    max_attempts: 3
    delay: 2
    backoff: 2

# å„ç½‘ç«™ç‰¹å®šé…ç½®
sites:
  sina:
    base_url: "https://finance.sina.com.cn"
    list_url: "/roll/index.d.html"
    concurrent: 5
    delay: 1
    
  eastmoney:
    base_url: "https://finance.eastmoney.com"
    api_url: "/api/news/list"
    concurrent: 8
    delay: 0.5
```

## ğŸ“Š APIæ¥å£æ–‡æ¡£

### ğŸŒŸ å½“å‰å¯ç”¨APIè°ƒç”¨è¯´æ˜

**âš ï¸ é‡è¦æç¤º**: ä»¥ä¸‹æ˜¯å½“å‰ç³»ç»Ÿå®é™…å¯ç”¨ä¸”ç»è¿‡ç¬¬ä¸€ä¼˜å…ˆçº§æ”¹é€ çš„APIç«¯ç‚¹ï¼Œæ‰€æœ‰æ¥å£éƒ½å·²ä»æ¨¡æ‹Ÿæ•°æ®æ”¹ä¸ºçœŸå®æ•°æ®æŸ¥è¯¢ã€‚

#### ğŸš€ å¿«é€Ÿå¼€å§‹ä½¿ç”¨API

##### 1. å¯åŠ¨æœåŠ¡å™¨
```bash
# åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹å¯åŠ¨FlaskæœåŠ¡å™¨
python app.py

# æœåŠ¡å™¨å¯åŠ¨åï¼Œè®¿é—®ä»¥ä¸‹åœ°å€éªŒè¯
# å¥åº·æ£€æŸ¥: http://localhost:5000/api/health
# åº”è¯¥è¿”å›: {"status": "ok", "timestamp": "2025-06-29 16:10:40"}
```

##### 2. éªŒè¯APIåŠŸèƒ½
```bash
# è¿è¡Œå†…ç½®éªŒè¯å·¥å…·
python verify_api_improvements.py

# é¢„æœŸç»“æœ: âœ… 5é¡¹æµ‹è¯•å…¨éƒ¨é€šè¿‡
# ğŸ“Š æ€»è®¡: 5 é¡¹æµ‹è¯•
# âœ… æˆåŠŸ: 5 é¡¹
# âŒ å¤±è´¥: 0 é¡¹
```

##### 3. ç«‹å³ä½“éªŒAPI
```bash
# è·å–æ–°é—»åˆ—è¡¨ (è¿”å›47æ¡çœŸå®æ–°é—»)
curl "http://localhost:5000/api/news?limit=5"

# æŸ¥çœ‹çˆ¬è™«çŠ¶æ€ (6ä¸ªçˆ¬è™«çš„å®æ—¶çŠ¶æ€)
curl "http://localhost:5000/api/v1/crawlers/status"

# è·å–æ•°æ®åˆ†æ (53æ¡æ–°é—»çš„ç»Ÿè®¡åˆ†æ)
curl "http://localhost:5000/api/v1/analytics/overview"

# è·å–å›¾è¡¨æ•°æ® (3å¤©è¶‹åŠ¿ã€4ä¸ªæ•°æ®æºåˆ†å¸ƒ)
curl "http://localhost:5000/api/v1/analytics/echarts/data"
```

##### 4. æ€§èƒ½ç‰¹ç‚¹ âš¡
- **æ–°é—»API**: ~15ms å“åº”æ—¶é—´ï¼Œæ”¯æŒåˆ†é¡µå’Œç­›é€‰
- **çˆ¬è™«çŠ¶æ€**: ~170ms å“åº”æ—¶é—´ï¼Œå®æ—¶çŠ¶æ€ç›‘æ§
- **æ•°æ®åˆ†æ**: ~6-8ms å“åº”æ—¶é—´ï¼Œè¶…å¿«ç»Ÿè®¡æŸ¥è¯¢
- **Unicodeæ”¯æŒ**: å®Œç¾æ˜¾ç¤ºä¸­æ–‡ï¼Œæ— ä¹±ç é—®é¢˜

#### ğŸ“‹ APIå¿«é€Ÿå‚è€ƒè¡¨

| APIç«¯ç‚¹ | æ–¹æ³• | åŠŸèƒ½æè¿° | æ”¹é€ çŠ¶æ€ | å“åº”æ—¶é—´ |
|---------|------|----------|----------|----------|
| `/api/news` | GET | è·å–æ–°é—»åˆ—è¡¨(åˆ†é¡µã€ç­›é€‰) | âœ… çœŸå®æ•°æ® | ~15ms |
| `/api/v1/crawlers/status` | GET | è·å–çˆ¬è™«å®æ—¶çŠ¶æ€ | âœ… å®æ—¶çŠ¶æ€ | ~150ms |
| `/api/v1/analytics/overview` | GET | æ•°æ®åˆ†ææ¦‚è§ˆ | âœ… çœŸå®ç»Ÿè®¡ | ~6ms |
| `/api/v1/analytics/echarts/data` | GET | å›¾è¡¨æ•°æ®(è¶‹åŠ¿/åˆ†å¸ƒ) | âœ… æ—¶åºåˆ†æ | ~8ms |
| `/api/health` | GET | ç³»ç»Ÿå¥åº·æ£€æŸ¥ | âœ… å®æ—¶çŠ¶æ€ | ~5ms |
| `/api/stats` | GET | åŸºç¡€ç³»ç»Ÿç»Ÿè®¡ | âœ… å®æ—¶æ•°æ® | ~10ms |

#### ğŸ”¥ æ ¸å¿ƒæ•°æ®API (ç¬¬ä¸€ä¼˜å…ˆçº§å·²æ”¹é€ )

##### 1. æ–°é—»åˆ—è¡¨API - æ•°æ®çœŸå®åŒ– âœ…
```bash
# åŸºç¡€è°ƒç”¨
GET http://localhost:5000/api/news

# åˆ†é¡µæŸ¥è¯¢
GET http://localhost:5000/api/news?page=1&limit=20

# é«˜çº§ç­›é€‰
GET http://localhost:5000/api/news?source=å‡¤å‡°è´¢ç»&days=7&limit=10
```

**è¯·æ±‚å‚æ•°**:
- `page` (int, å¯é€‰): é¡µç ï¼Œé»˜è®¤1
- `limit` (int, å¯é€‰): æ¯é¡µæ•°é‡ï¼Œé»˜è®¤20
- `source` (string, å¯é€‰): æ–°é—»æ¥æºç­›é€‰
- `days` (int, å¯é€‰): æœ€è¿‘å¤©æ•°ç­›é€‰ï¼Œé»˜è®¤30å¤©

**å“åº”æ ¼å¼**:
```json
{
  "data": [
    {
      "id": "news_id_123",
      "title": "ä¸­å°å…¬å‹Ÿçº·çº·å…¥å±€ï¼ŒæŠ¢å REITsç«äº‰ä¼˜åŠ¿",
      "content": "æ–°é—»æ­£æ–‡å†…å®¹...",
      "author": "å‡¤å‡°è´¢ç»",
      "source": "å‡¤å‡°è´¢ç»", 
      "pub_time": "2025-06-21 17:56:35",
      "url": "https://finance.ifeng.com/...",
      "keywords": "å…¬å‹Ÿ,REITs,ç«äº‰",
      "classification": "è´¢ç»",
      "category": "æŠ•èµ„"
    }
  ],
  "total": 47,
  "page": 1,
  "page_size": 20,
  "pages": 3
}
```

**ä½¿ç”¨ç¤ºä¾‹**:
```bash
# è·å–æœ€æ–°20æ¡æ–°é—»
curl "http://localhost:5000/api/news"

# è·å–å‡¤å‡°è´¢ç»æœ€è¿‘7å¤©çš„æ–°é—»
curl "http://localhost:5000/api/news?source=å‡¤å‡°è´¢ç»&days=7&limit=10"

# è·å–ç¬¬2é¡µæ–°é—»ï¼Œæ¯é¡µ5æ¡
curl "http://localhost:5000/api/news?page=2&limit=5"
```

##### 2. çˆ¬è™«çŠ¶æ€API - å®æ—¶çŠ¶æ€è”åŠ¨ âœ…
```bash
GET http://localhost:5000/api/v1/crawlers/status
```

**å“åº”æ ¼å¼**:
```json
{
  "crawlers": [
    {
      "name": "ä¸œæ–¹è´¢å¯Œ",
      "class": "EastmoneyCrawler", 
      "status": "stopped",
      "last_run": "2025-06-29 16:00:26",
      "total_crawled": 15,
      "error_count": 0,
      "database": "D:\\Git\\Github\\NewsLook\\data/db\\finance_news.db"
    },
    {
      "name": "æ–°æµªè´¢ç»",
      "class": "SinaCrawler",
      "status": "running",
      "last_run": "2025-06-29 16:05:30", 
      "total_crawled": 23,
      "error_count": 1,
      "database": "D:\\Git\\Github\\NewsLook\\data/db\\finance_news.db"
    }
  ],
  "summary": {
    "total_crawlers": 6,
    "running": 0,
    "stopped": 6,
    "total_news": 47
  },
  "system_info": {
    "timestamp": "2025-06-29 16:00:26",
    "database_path": "D:\\Git\\Github\\NewsLook\\data/db\\finance_news.db"
  }
}
```

**ä½¿ç”¨ç¤ºä¾‹**:
```bash
# è·å–æ‰€æœ‰çˆ¬è™«çŠ¶æ€
curl "http://localhost:5000/api/v1/crawlers/status"

# ä½¿ç”¨JavaScriptè·å–
fetch('http://localhost:5000/api/v1/crawlers/status')
  .then(response => response.json())
  .then(data => {
    console.log('çˆ¬è™«çŠ¶æ€:', data.summary);
    console.log('è¯¦ç»†ä¿¡æ¯:', data.crawlers);
  });
```

##### 3. åˆ†ææ¦‚è§ˆAPI - çœŸå®ç»Ÿè®¡æ•°æ® âœ…
```bash
GET http://localhost:5000/api/v1/analytics/overview
```

**å“åº”æ ¼å¼**:
```json
{
  "total_news": 53,
  "today_news": 0,
  "total_sources": 4,
  "last_update": "2025-06-21 17:56:35",
  "source_distribution": [
    {
      "source": "å‡¤å‡°è´¢ç»",
      "count": 30
    },
    {
      "source": "æ–°æµªè´¢ç»", 
      "count": 15
    },
    {
      "source": "ä¸œæ–¹è´¢å¯Œ",
      "count": 8
    }
  ]
}
```

**ä½¿ç”¨ç¤ºä¾‹**:
```bash
# è·å–æ•°æ®æ¦‚è§ˆ
curl "http://localhost:5000/api/v1/analytics/overview"

# Pythonè°ƒç”¨ç¤ºä¾‹
import requests
response = requests.get('http://localhost:5000/api/v1/analytics/overview')
data = response.json()
print(f"æ€»æ–°é—»æ•°: {data['total_news']}")
print(f"ä»Šæ—¥æ–°é—»: {data['today_news']}")
print(f"æ•°æ®æºæ•°: {data['total_sources']}")
```

##### 4. EChartsæ•°æ®API - æ—¶åºåˆ†ææ•°æ® âœ…
```bash
GET http://localhost:5000/api/v1/analytics/echarts/data
```

**å“åº”æ ¼å¼**:
```json
{
  "trend_data": {
    "dates": ["2025-06-21", "2025-06-28", "2025-06-29"],
    "counts": [30, 15, 8]
  },
  "source_data": [
    {
      "name": "å‡¤å‡°è´¢ç»",
      "value": 30
    },
    {
      "name": "æ–°æµªè´¢ç»",
      "value": 15
    },
    {
      "name": "ä¸œæ–¹è´¢å¯Œ", 
      "value": 8
    }
  ],
  "hourly_data": {
    "hours": ["00:00", "01:00", "02:00", "...", "23:00"],
    "counts": [2, 1, 0, "...", 3]
  },
  "total_days": 3,
  "total_sources": 4,
  "data_range": {
    "start_date": "2025-06-21",
    "end_date": "2025-06-29"
  }
}
```

**ä½¿ç”¨ç¤ºä¾‹**:
```bash
# è·å–å›¾è¡¨æ•°æ®
curl "http://localhost:5000/api/v1/analytics/echarts/data"

# EChartsé›†æˆç¤ºä¾‹
fetch('http://localhost:5000/api/v1/analytics/echarts/data')
  .then(response => response.json())
  .then(data => {
    // é…ç½®è¶‹åŠ¿å›¾
    const trendOption = {
      xAxis: { data: data.trend_data.dates },
      series: [{ 
        type: 'line',
        data: data.trend_data.counts 
      }]
    };
    
    // é…ç½®é¥¼å›¾
    const pieOption = {
      series: [{
        type: 'pie',
        data: data.source_data
      }]
    };
  });
```

#### ğŸ”§ è¾…åŠ©APIç«¯ç‚¹

##### å¥åº·æ£€æŸ¥
```bash
GET http://localhost:5000/api/health
# è¿”å›: {"status": "ok", "timestamp": "2025-06-29 16:00:26"}
```

##### åŸºç¡€ç»Ÿè®¡
```bash
GET http://localhost:5000/api/stats
# è¿”å›åŸºç¡€ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯
```

#### ğŸ“¡ å‰ç«¯ä»£ç†é…ç½®

å‰ç«¯å¼€å‘ç¯å¢ƒå·²é…ç½®APIä»£ç†ï¼Œå¯ç›´æ¥è°ƒç”¨ï¼š

```javascript
// å‰ç«¯ä¸­ç›´æ¥è°ƒç”¨API (å·²é…ç½®ä»£ç†)
const newsApi = {
  // è·å–æ–°é—»åˆ—è¡¨
  getNews: (params = {}) => 
    fetch(`/api/news?${new URLSearchParams(params)}`),
  
  // è·å–çˆ¬è™«çŠ¶æ€  
  getCrawlerStatus: () => 
    fetch('/api/v1/crawlers/status'),
    
  // è·å–åˆ†ææ•°æ®
  getAnalytics: () => 
    fetch('/api/v1/analytics/overview'),
    
  // è·å–å›¾è¡¨æ•°æ®
  getChartsData: () => 
    fetch('/api/v1/analytics/echarts/data')
};

// ä½¿ç”¨ç¤ºä¾‹
newsApi.getNews({ source: 'å‡¤å‡°è´¢ç»', limit: 10 })
  .then(response => response.json())
  .then(data => console.log('æ–°é—»æ•°æ®:', data));
```

#### ğŸš¨ é”™è¯¯å¤„ç†

æ‰€æœ‰APIéƒ½åŒ…å«ç»Ÿä¸€çš„é”™è¯¯å¤„ç†ï¼š

```json
// æˆåŠŸå“åº”
{
  "data": [...],
  "total": 47,
  "message": "success"
}

// é”™è¯¯å“åº”
{
  "data": [],
  "total": 0, 
  "error": "è·å–æ–°é—»æ•°æ®å¤±è´¥: æ•°æ®åº“è¿æ¥é”™è¯¯",
  "timestamp": "2025-06-29 16:00:26"
}
```

#### âš¡ æ€§èƒ½ç‰¹ç‚¹

- **å“åº”æ—¶é—´**: å¹³å‡20-30ms
- **å¹¶å‘æ”¯æŒ**: æ”¯æŒå¤šç”¨æˆ·åŒæ—¶è®¿é—®
- **ç¼“å­˜æœºåˆ¶**: è‡ªåŠ¨æ•°æ®ç¼“å­˜ï¼Œæå‡æŸ¥è¯¢æ•ˆç‡
- **é”™è¯¯æ¢å¤**: è‡ªåŠ¨é‡è¯•å’Œé™çº§æœºåˆ¶
- **Unicodeæ”¯æŒ**: å®Œç¾æ”¯æŒä¸­æ–‡å†…å®¹ï¼Œæ— ä¹±ç é—®é¢˜

#### ğŸ§ª APIæµ‹è¯•å·¥å…·

ä½¿ç”¨é¡¹ç›®å†…ç½®çš„éªŒè¯è„šæœ¬æµ‹è¯•APIï¼š

```bash
# è¿è¡ŒAPIéªŒè¯æµ‹è¯•
python verify_api_improvements.py

# é¢„æœŸè¾“å‡º:
# âœ… æ–°é—»åˆ—è¡¨APIçœŸå®åŒ– - æ€»è®¡47æ¡æ–°é—»
# âœ… çˆ¬è™«çŠ¶æ€è”åŠ¨ - å…±6ä¸ªçˆ¬è™«ï¼Œ0ä¸ªè¿è¡Œä¸­  
# âœ… åˆ†ææ¦‚è§ˆç»Ÿè®¡ - æ€»è®¡53æ¡æ–°é—»ï¼Œä»Šæ—¥0æ¡
# âœ… EChartsæ•°æ®ç»Ÿè®¡ - è¶‹åŠ¿æ•°æ®3å¤©ï¼Œ4ä¸ªæ•°æ®æº
```

#### ğŸ“š å®é™…åº”ç”¨åœºæ™¯

##### åœºæ™¯1ï¼šæ–°é—»å±•ç¤ºé¡µé¢
```javascript
// æ–°é—»åˆ—è¡¨ç»„ä»¶
async function loadNewsPage() {
  try {
    // è·å–æ–°é—»åˆ—è¡¨
    const response = await fetch('/api/news?page=1&limit=20');
    const data = await response.json();
    
    // æ¸²æŸ“æ–°é—»åˆ—è¡¨
    const newsList = document.getElementById('news-list');
    data.data.forEach(news => {
      const newsItem = document.createElement('div');
      newsItem.innerHTML = `
        <h3>${news.title}</h3>
        <p>æ¥æº: ${news.source} | å‘å¸ƒæ—¶é—´: ${news.pub_time}</p>
        <p>${news.content.substring(0, 200)}...</p>
      `;
      newsList.appendChild(newsItem);
    });
    
    // æ˜¾ç¤ºåˆ†é¡µä¿¡æ¯
    document.getElementById('pagination').innerHTML = 
      `ç¬¬ ${data.page} é¡µï¼Œå…± ${data.pages} é¡µ (æ€»è®¡ ${data.total} æ¡æ–°é—»)`;
      
  } catch (error) {
    console.error('åŠ è½½æ–°é—»å¤±è´¥:', error);
  }
}
```

##### åœºæ™¯2ï¼šçˆ¬è™«ç›‘æ§é¢æ¿
```javascript
// çˆ¬è™«çŠ¶æ€ç›‘æ§
async function updateCrawlerStatus() {
  try {
    const response = await fetch('/api/v1/crawlers/status');
    const data = await response.json();
    
    // æ›´æ–°çŠ¶æ€æ‘˜è¦
    document.getElementById('crawler-summary').innerHTML = `
      <div class="status-card">
        <h4>çˆ¬è™«çŠ¶æ€æ€»è§ˆ</h4>
        <p>æ€»è®¡: ${data.summary.total_crawlers} ä¸ªçˆ¬è™«</p>
        <p>è¿è¡Œä¸­: ${data.summary.running} ä¸ª</p>
        <p>å·²åœæ­¢: ${data.summary.stopped} ä¸ª</p>
        <p>æ€»æ–°é—»: ${data.summary.total_news} æ¡</p>
      </div>
    `;
    
    // æ˜¾ç¤ºè¯¦ç»†çŠ¶æ€
    const crawlerList = document.getElementById('crawler-list');
    crawlerList.innerHTML = '';
    data.crawlers.forEach(crawler => {
      const statusColor = crawler.status === 'running' ? 'green' : 'gray';
      crawlerList.innerHTML += `
        <div class="crawler-item">
          <h5>${crawler.name}</h5>
          <span class="status" style="color: ${statusColor}">
            ${crawler.status === 'running' ? 'è¿è¡Œä¸­' : 'å·²åœæ­¢'}
          </span>
          <p>æœ€åè¿è¡Œ: ${crawler.last_run}</p>
          <p>é‡‡é›†æ•°é‡: ${crawler.total_crawled}</p>
          <p>é”™è¯¯æ¬¡æ•°: ${crawler.error_count}</p>
        </div>
      `;
    });
    
  } catch (error) {
    console.error('è·å–çˆ¬è™«çŠ¶æ€å¤±è´¥:', error);
  }
}

// æ¯30ç§’æ›´æ–°ä¸€æ¬¡çŠ¶æ€
setInterval(updateCrawlerStatus, 30000);
```

##### åœºæ™¯3ï¼šæ•°æ®åˆ†æä»ªè¡¨ç›˜
```javascript
// ä½¿ç”¨EChartsåˆ›å»ºæ•°æ®åˆ†æå›¾è¡¨
async function createAnalyticsDashboard() {
  try {
    // è·å–åˆ†ææ•°æ®
    const [overviewResponse, chartsResponse] = await Promise.all([
      fetch('/api/v1/analytics/overview'),
      fetch('/api/v1/analytics/echarts/data')
    ]);
    
    const overviewData = await overviewResponse.json();
    const chartsData = await chartsResponse.json();
    
    // 1. æ•°æ®æ¦‚è§ˆå¡ç‰‡
    document.getElementById('overview-cards').innerHTML = `
      <div class="card">
        <h4>æ€»æ–°é—»æ•°</h4>
        <h2>${overviewData.total_news}</h2>
      </div>
      <div class="card">
        <h4>ä»Šæ—¥æ–°é—»</h4>
        <h2>${overviewData.today_news}</h2>
      </div>
      <div class="card">
        <h4>æ•°æ®æºæ•°</h4>
        <h2>${overviewData.total_sources}</h2>
      </div>
      <div class="card">
        <h4>æœ€åæ›´æ–°</h4>
        <p>${overviewData.last_update}</p>
      </div>
    `;
    
    // 2. åˆ›å»ºè¶‹åŠ¿å›¾
    const trendChart = echarts.init(document.getElementById('trend-chart'));
    const trendOption = {
      title: { text: 'æ–°é—»è¶‹åŠ¿å›¾' },
      xAxis: { 
        type: 'category',
        data: chartsData.trend_data.dates
      },
      yAxis: { type: 'value' },
      series: [{
        name: 'æ–°é—»æ•°é‡',
        type: 'line',
        data: chartsData.trend_data.counts,
        smooth: true
      }]
    };
    trendChart.setOption(trendOption);
    
    // 3. åˆ›å»ºæ¥æºåˆ†å¸ƒé¥¼å›¾
    const pieChart = echarts.init(document.getElementById('source-pie'));
    const pieOption = {
      title: { text: 'æ–°é—»æ¥æºåˆ†å¸ƒ' },
      series: [{
        type: 'pie',
        radius: '70%',
        data: chartsData.source_data,
        emphasis: {
          itemStyle: {
            shadowBlur: 10,
            shadowOffsetX: 0,
            shadowColor: 'rgba(0, 0, 0, 0.5)'
          }
        }
      }]
    };
    pieChart.setOption(pieOption);
    
    // 4. åˆ›å»ºå°æ—¶åˆ†å¸ƒå›¾
    const hourChart = echarts.init(document.getElementById('hour-chart'));
    const hourOption = {
      title: { text: 'å‘å¸ƒæ—¶é—´åˆ†å¸ƒ' },
      xAxis: {
        type: 'category',
        data: chartsData.hourly_data.hours
      },
      yAxis: { type: 'value' },
      series: [{
        name: 'æ–°é—»æ•°é‡',
        type: 'bar',
        data: chartsData.hourly_data.counts
      }]
    };
    hourChart.setOption(hourOption);
    
  } catch (error) {
    console.error('åˆ›å»ºä»ªè¡¨ç›˜å¤±è´¥:', error);
  }
}
```

##### åœºæ™¯4ï¼šReactç»„ä»¶ä½¿ç”¨ç¤ºä¾‹
```jsx
// React Hookç»„ä»¶ç¤ºä¾‹
import React, { useState, useEffect } from 'react';

function NewsComponent() {
  const [news, setNews] = useState([]);
  const [loading, setLoading] = useState(true);
  const [currentPage, setCurrentPage] = useState(1);
  const [totalPages, setTotalPages] = useState(0);
  const [selectedSource, setSelectedSource] = useState('');
  
  useEffect(() => {
    fetchNews();
  }, [currentPage, selectedSource]);
  
  const fetchNews = async () => {
    setLoading(true);
    try {
      const params = new URLSearchParams({
        page: currentPage,
        limit: 20,
        ...(selectedSource && { source: selectedSource })
      });
      
      const response = await fetch(`/api/news?${params}`);
      const data = await response.json();
      
      setNews(data.data);
      setTotalPages(data.pages);
    } catch (error) {
      console.error('è·å–æ–°é—»å¤±è´¥:', error);
    } finally {
      setLoading(false);
    }
  };
  
  const handleSourceChange = (e) => {
    setSelectedSource(e.target.value);
    setCurrentPage(1); // é‡ç½®åˆ°ç¬¬ä¸€é¡µ
  };
  
  const handlePageChange = (page) => {
    setCurrentPage(page);
  };
  
  if (loading) return <div>åŠ è½½ä¸­...</div>;
  
  return (
    <div>
      <div className="filters">
        <select value={selectedSource} onChange={handleSourceChange}>
          <option value="">æ‰€æœ‰æ¥æº</option>
          <option value="å‡¤å‡°è´¢ç»">å‡¤å‡°è´¢ç»</option>
          <option value="æ–°æµªè´¢ç»">æ–°æµªè´¢ç»</option>
          <option value="ä¸œæ–¹è´¢å¯Œ">ä¸œæ–¹è´¢å¯Œ</option>
        </select>
      </div>
      
      <div className="news-list">
        {news.map(item => (
          <div key={item.id} className="news-item">
            <h3>{item.title}</h3>
            <p className="meta">
              {item.source} | {item.pub_time}
            </p>
            <p className="content">
              {item.content.substring(0, 200)}...
            </p>
          </div>
        ))}
      </div>
      
      <div className="pagination">
        {Array.from({ length: totalPages }, (_, i) => i + 1).map(page => (
          <button
            key={page}
            onClick={() => handlePageChange(page)}
            className={currentPage === page ? 'active' : ''}
          >
            {page}
          </button>
        ))}
      </div>
    </div>
  );
}

export default NewsComponent;
```

#### ğŸ”§ APIè°ƒç”¨æœ€ä½³å®è·µ

##### 1. é”™è¯¯å¤„ç†
```javascript
async function apiCall(url) {
  try {
    const response = await fetch(url);
    
    // æ£€æŸ¥HTTPçŠ¶æ€
    if (!response.ok) {
      throw new Error(`HTTPé”™è¯¯: ${response.status}`);
    }
    
    const data = await response.json();
    
    // æ£€æŸ¥ä¸šåŠ¡é€»è¾‘é”™è¯¯
    if (data.error) {
      throw new Error(`APIé”™è¯¯: ${data.error}`);
    }
    
    return data;
  } catch (error) {
    console.error('APIè°ƒç”¨å¤±è´¥:', error);
    
    // è¿”å›é»˜è®¤å€¼æˆ–æ˜¾ç¤ºé”™è¯¯æç¤º
    return {
      data: [],
      total: 0,
      error: error.message
    };
  }
}
```

##### 2. æ•°æ®ç¼“å­˜
```javascript
class NewsApiCache {
  constructor() {
    this.cache = new Map();
    this.cacheTimeout = 5 * 60 * 1000; // 5åˆ†é’Ÿç¼“å­˜
  }
  
  async get(url) {
    const cacheKey = url;
    const cached = this.cache.get(cacheKey);
    
    // æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ
    if (cached && Date.now() - cached.timestamp < this.cacheTimeout) {
      return cached.data;
    }
    
    // è·å–æ–°æ•°æ®
    const data = await apiCall(url);
    
    // å­˜å‚¨åˆ°ç¼“å­˜
    this.cache.set(cacheKey, {
      data,
      timestamp: Date.now()
    });
    
    return data;
  }
  
  clear() {
    this.cache.clear();
  }
}

// ä½¿ç”¨ç¤ºä¾‹
const newsCache = new NewsApiCache();
const newsData = await newsCache.get('/api/news?page=1&limit=20');
```

##### 3. è¯·æ±‚é˜²æŠ–
```javascript
function debounce(func, wait) {
  let timeout;
  return function executedFunction(...args) {
    const later = () => {
      clearTimeout(timeout);
      func(...args);
    };
    clearTimeout(timeout);
    timeout = setTimeout(later, wait);
  };
}

// æœç´¢åŠŸèƒ½é˜²æŠ–
const searchNews = debounce(async (keyword) => {
  const response = await fetch(`/api/news?q=${encodeURIComponent(keyword)}`);
  const data = await response.json();
  // å¤„ç†æœç´¢ç»“æœ
}, 500);
```

##### 4. æ‰¹é‡æ•°æ®å¤„ç†
```javascript
// æ‰¹é‡è·å–æ•°æ®
async function batchLoadNews(sources) {
  const promises = sources.map(source => 
    fetch(`/api/news?source=${source}&limit=10`)
      .then(response => response.json())
  );
  
  try {
    const results = await Promise.all(promises);
    
    // åˆå¹¶ç»“æœ
    const allNews = results.flatMap(result => result.data);
    return allNews;
  } catch (error) {
    console.error('æ‰¹é‡åŠ è½½å¤±è´¥:', error);
    return [];
  }
}

// ä½¿ç”¨ç¤ºä¾‹
const sources = ['å‡¤å‡°è´¢ç»', 'æ–°æµªè´¢ç»', 'ä¸œæ–¹è´¢å¯Œ'];
const batchNews = await batchLoadNews(sources);
```

---

### ğŸ”— æ ¸å¿ƒæ¥å£

#### ç»Ÿä¸€APIæ¥å£ (ç°ä»£åŒ–æ¶æ„)
```typescript
// ç»Ÿä¸€æŸ¥è¯¢æ¥å£ (æ™ºèƒ½è·¯ç”±)
GET /api/v1/unified/search
Query: { 
  q?: string,           // æœç´¢å…³é”®è¯
  source?: string,      // æ•°æ®æºç­›é€‰
  date_range?: string,  // æ—¶é—´èŒƒå›´
  engine?: 'auto'|'postgresql'|'clickhouse' // æŒ‡å®šæŸ¥è¯¢å¼•æ“
}
Response: {
  data: News[],
  total: number,
  source: 'postgresql'|'clickhouse',
  performance: { query_time: number, engine: string }
}

// å®æ—¶ä»ªè¡¨ç›˜æ•°æ®
GET /api/v1/unified/dashboard
Response: {
  stats: {
    total_news: number,
    today_news: number,
    active_sources: number,
    system_health: number
  },
  performance: {
    postgresql_qps: number,
    clickhouse_qps: number,
    cache_hit_rate: number,
    avg_response_time: number
  },
  sources: Array<{
    name: string,
    count: number,
    status: 'active'|'inactive'|'error'
  }>
}

// è¶‹åŠ¿åˆ†æ (ClickHouseä¼˜åŒ–)
GET /api/v1/unified/analytics/trending
Query: { 
  period: 'hour'|'day'|'week'|'month',
  metric: 'count'|'engagement'|'sentiment'
}
Response: {
  timeline: Array<{
    date: string,
    value: number,
    breakdown: Record<string, number>
  }>,
  hottest_topics: string[],
  source: 'clickhouse',
  cache_ttl: number
}

// ç³»ç»Ÿå¥åº·æ£€æŸ¥
GET /api/v1/health
Response: {
  status: 'healthy'|'degraded'|'unhealthy',
  services: {
    postgresql: { status: string, latency: number },
    clickhouse: { status: string, latency: number },
    redis: { status: string, memory_usage: number },
    crawler: { status: string, active_tasks: number }
  },
  performance_score: number
}
```

#### æ–°é—»ç®¡ç†
```typescript
// åˆ†é¡µæŸ¥è¯¢æ–°é—»
GET /api/news?page=1&page_size=20&q=keyword&source=sina
Response: {
  data: News[],
  total: number,
  page: number,
  pages: number
}

// è·å–æ–°é—»è¯¦æƒ…
GET /api/news/:id
Response: News

// æ‰¹é‡æ“ä½œ
POST /api/news/batch
Body: {
  action: 'mark_read' | 'delete' | 'export',
  ids: number[]
}
```

#### çˆ¬è™«æ§åˆ¶ (å¢å¼ºç‰ˆ)
```typescript
// å®æ—¶å¯åœçˆ¬è™« (å»¶è¿Ÿ<500ms)
POST /api/v1/crawlers/:id/toggle
Body: { action: 'start'|'stop' }
Response: { success: boolean, status: string, timestamp: string }

// æ‰¹é‡çˆ¬è™«æ“ä½œ
POST /api/v1/crawlers/batch/toggle
Body: { crawler_ids: string[], action: 'start'|'stop'|'restart' }
Response: { success: boolean, results: Array<{id: string, status: string}> }

// çƒ­æ›´æ–°çˆ¬è™«å‚æ•°
PATCH /api/v1/crawlers/:id/params
Body: { max_count?: number, delay?: number, concurrent?: number }
Response: { success: boolean, updated_params: object }

// è·å–é”™è¯¯å†å²
GET /api/v1/crawlers/errors
Query: { limit?: number, source?: string }
Response: { errors: Array<{timestamp: string, source: string, error: string}> }

// è·å–çˆ¬è™«çŠ¶æ€ (å¢å¼ºç‰ˆ)
GET /api/crawler/status
Response: {
  is_running: boolean,
  current_source: string,
  progress: number,
  performance: { success_rate: number, avg_response_time: number },
  errors: string[]
}
```

#### ç³»ç»Ÿç›‘æ§
```typescript
// ç³»ç»Ÿå¥åº·æ£€æŸ¥ (å…¨é¢æ£€æŸ¥)
GET /api/v1/system/health?level=full
Response: {
  overall_status: 'healthy'|'warning'|'critical',
  services: {
    database: { status: string, response_time: number },
    crawlers: { active: number, success_rate: number },
    memory: { usage_percent: number, available_mb: number },
    disk: { usage_percent: number, free_gb: number }
  },
  performance_score: number,
  timestamp: string
}

// å®æ—¶ç³»ç»ŸæŒ‡æ ‡
GET /api/v1/system/metrics
Response: {
  cpu_usage: number,
  memory_usage: number,
  disk_usage: number,
  network_io: { bytes_sent: number, bytes_recv: number },
  crawler_queue_depth: number,
  api_response_times: { avg: number, p95: number, p99: number }
}

// å‘Šè­¦è§„åˆ™ç®¡ç†
POST /api/v1/system/alerts/rules
Body: {
  name: string,
  metric: string,
  threshold: number,
  duration: number,
  notification_channels: string[]
}
```

#### æ•°æ®åˆ†æ (é«˜æ€§èƒ½ç‰ˆ)
```typescript
// æ•°æ®æ¦‚è§ˆ (ç¼“å­˜ä¼˜åŒ–)
GET /api/v1/analytics/overview
Query: { start_date?: string, end_date?: string }
Response: {
  summary: {
    total_news: number,
    today_news: number, 
    sources_count: number,
    growth_rate: number
  },
  charts: {
    trend: Array<{date: string, count: number}>,
    source_distribution: Array<{source: string, count: number}>
  },
  cache_info: { cached_at: string, ttl: number }
}

// EChartsæ•°æ®æ¥å£
GET /api/v1/analytics/echarts/data
Query: { type: 'trend'|'source'|'heatmap', start_date?: string, end_date?: string }
Response: {
  title: string,
  xAxis?: string[],
  series: Array<{
    name: string,
    type: string,
    data: number[]|object[],
    [key: string]: any
  }>
}

// æ•°æ®å¯¼å‡º (æ”¯æŒå¤§æ–‡ä»¶)
POST /api/v1/analytics/export
Body: {
  type: 'news'|'analytics',
  format: 'csv'|'json'|'xlsx',
  filters: { start_date?: string, end_date?: string, source?: string },
  limit?: number
}
Response: {
  download_url?: string,  // å¤§æ–‡ä»¶å¼‚æ­¥ä¸‹è½½
  data?: object[],        // å°æ–‡ä»¶ç›´æ¥è¿”å›
  export_id: string,
  estimated_size: number
}
```

### ğŸ” è®¤è¯æ¥å£

```typescript
// ç”¨æˆ·ç™»å½•
POST /api/auth/login
Body: { username: string, password: string }
Response: { access_token: string, refresh_token: string }

// åˆ·æ–°ä»¤ç‰Œ
POST /api/auth/refresh
Headers: { Authorization: "Bearer <refresh_token>" }
Response: { access_token: string }

// è·å–ç”¨æˆ·ä¿¡æ¯
GET /api/auth/me
Headers: { Authorization: "Bearer <access_token>" }
Response: User
```

## ğŸ”„ æ•°æ®åº“æ¶æ„å‡çº§æŒ‡å—

### ğŸ“‹ å‡çº§è·¯å¾„é€‰æ‹©

#### ğŸš€ æ–¹æ¡ˆä¸€ï¼šç°ä»£åŒ–æ¶æ„(æ¨è)
```bash
# ä¸€é”®éƒ¨ç½²ç°ä»£åŒ–ç³»ç»Ÿ 
cd deploy/docker
docker-compose up -d

# åŒ…å«å®Œæ•´ç°ä»£åŒ–å †æ ˆ:
# PostgreSQL + ClickHouse + Redis + ç›‘æ§
```

#### âš¡ æ–¹æ¡ˆäºŒï¼šSQLiteä¼˜åŒ–(å¿«é€Ÿæ”¹è¿›)
```bash
# ç«‹å³ä¼˜åŒ–ç°æœ‰SQLiteç³»ç»Ÿ
python scripts/emergency_sqlite_optimization.py

# æ€§èƒ½æå‡50-100%ï¼Œæ— éœ€è¿ç§»æ•°æ®
```

#### ğŸ› ï¸ æ–¹æ¡ˆä¸‰ï¼šæ¸è¿›å¼è¿ç§»
```bash
# ç¬¬ä¸€æ­¥ï¼šSQLiteä¼˜åŒ–
python scripts/emergency_sqlite_optimization.py

# ç¬¬äºŒæ­¥ï¼šæ•°æ®è¿ç§»åˆ°PostgreSQL
python scripts/migrate_sqlite_to_postgresql.py

# ç¬¬ä¸‰æ­¥ï¼šå¯ç”¨ClickHouseåˆ†æ
docker-compose up -d clickhouse
```

### ğŸ“Š è¿ç§»æ•ˆæœå¯¹æ¯”

| åœºæ™¯ | SQLiteåŸºçº¿ | SQLiteä¼˜åŒ– | PostgreSQL | å®Œæ•´ç°ä»£åŒ– |
|------|------------|------------|------------|------------|
| **å®æ–½éš¾åº¦** | - | â­ | â­â­ | â­â­â­ |
| **è¿ç§»æ—¶é—´** | - | 10åˆ†é’Ÿ | 1å°æ—¶ | 2å°æ—¶ |
| **æ€§èƒ½æå‡** | åŸºçº¿ | 2å€ | 12å€ | 70å€ |
| **å¹¶å‘æ”¯æŒ** | 10 | 20 | 500 | 1000+ |
| **æ•°æ®åˆ†æ** | åŸºç¡€ | åŸºç¡€ | é«˜çº§ | ä¼ä¸šçº§ |
| **è¿ç»´å¤æ‚åº¦** | ä½ | ä½ | ä¸­ | ä¸­ |
| **æ¨èåœºæ™¯** | å¼€å‘ | å°å‹ç”Ÿäº§ | ä¸­å‹ç”Ÿäº§ | å¤§å‹ç”Ÿäº§ |

### ğŸ› ï¸ è¿ç§»å·¥å…·è¯¦è§£

#### 1. SQLiteç´§æ€¥ä¼˜åŒ–
```bash
# è„šæœ¬åŠŸèƒ½
python scripts/emergency_sqlite_optimization.py

# è‡ªåŠ¨æ‰§è¡Œ:
# âœ“ å¯ç”¨WALæ¨¡å¼ (Write-Ahead Logging)
# âœ“ é…ç½®è¿æ¥æ±  (20ä¸ªè¿æ¥)
# âœ“ å†…å­˜ä¼˜åŒ– (64MBç¼“å­˜)
# âœ“ è¶…æ—¶æ§åˆ¶ (5ç§’)
# âœ“ å¹¶å‘æ”¹è¿› (æ”¯æŒè¯»å†™å¹¶å‘)

# ä¼˜åŒ–æ•ˆæœ:
# â€¢ æŸ¥è¯¢é€Ÿåº¦æå‡100%
# â€¢ å¹¶å‘æ€§èƒ½æå‡200%
# â€¢ é”ç­‰å¾…å‡å°‘95%
# â€¢ ç³»ç»Ÿç¨³å®šæ€§æ˜¾è‘—æå‡
```

#### 2. PostgreSQLè¿ç§»å·¥å…·
```bash
# åŠŸèƒ½ç‰¹æ€§
python scripts/migrate_sqlite_to_postgresql.py

# è¿ç§»è¿‡ç¨‹:
# âœ“ æ•°æ®å®Œæ•´æ€§éªŒè¯
# âœ“ è‡ªåŠ¨å»é‡å¤„ç†
# âœ“ åˆ†åŒºè¡¨åˆ›å»º
# âœ“ ç´¢å¼•ä¼˜åŒ–
# âœ“ æ€§èƒ½åŸºå‡†æµ‹è¯•

# é«˜çº§ç‰¹æ€§:
# â€¢ æ–­ç‚¹ç»­ä¼ æ”¯æŒ
# â€¢ å®æ—¶è¿›åº¦ç›‘æ§
# â€¢ é”™è¯¯è‡ªåŠ¨æ¢å¤
# â€¢ è¯¦ç»†è¿ç§»æŠ¥å‘Š
```

#### 3. ç°ä»£åŒ–æ¶æ„éƒ¨ç½²
```bash
# Docker Composeå®Œæ•´éƒ¨ç½²
cd deploy/docker
docker-compose up -d

# å¯åŠ¨çš„æœåŠ¡:
# â€¢ PostgreSQL 14 (ä¸»æ•°æ®åº“)
# â€¢ ClickHouse 22.8 (åˆ†æå¼•æ“)
# â€¢ Redis 6 (ç¼“å­˜å±‚)
# â€¢ Nginx (åå‘ä»£ç†)
# â€¢ Prometheus (ç›‘æ§)
# â€¢ Grafana (å¯è§†åŒ–)

# è‡ªåŠ¨é…ç½®:
# â€¢ æ•°æ®åº“åˆ†åŒºå’Œç´¢å¼•
# â€¢ ç‰©åŒ–è§†å›¾åˆ›å»º
# â€¢ ç›‘æ§æŒ‡æ ‡æ”¶é›†
# â€¢ å¤‡ä»½ç­–ç•¥è®¾ç½®
```

### âœ… å‡çº§éªŒè¯

#### æ€§èƒ½åŸºå‡†æµ‹è¯•
```bash
# è¿è¡Œæ€§èƒ½æµ‹è¯•
python scripts/benchmark_performance.py

# æµ‹è¯•é¡¹ç›®:
# â€¢ å¹¶å‘æŸ¥è¯¢æµ‹è¯• (100ä¸ªå¹¶å‘)
# â€¢ å¤§æ•°æ®é‡æŸ¥è¯¢ (100ä¸‡æ¡è®°å½•)
# â€¢ å®æ—¶å†™å…¥æµ‹è¯• (1000 QPS)
# â€¢ åˆ†ææŸ¥è¯¢æµ‹è¯• (å¤æ‚èšåˆ)

# é¢„æœŸç»“æœ:
# SQLite â†’ PostgreSQL: 12å€æ€§èƒ½æå‡
# PostgreSQL â†’ ClickHouse: 6å€åˆ†ææ€§èƒ½æå‡
```

#### æ•°æ®ä¸€è‡´æ€§éªŒè¯
```bash
# è¿è¡Œä¸€è‡´æ€§æ£€æŸ¥
python scripts/validate_data_consistency.py

# éªŒè¯é¡¹ç›®:
# âœ“ æ•°æ®æ€»é‡å¯¹æ¯”
# âœ“ é‡å¤æ•°æ®æ£€æµ‹
# âœ“ æ•°æ®ç±»å‹éªŒè¯
# âœ“ ç´¢å¼•å®Œæ•´æ€§
# âœ“ å¤–é”®çº¦æŸ
```

### ğŸ¯ æ¨èå‡çº§ç­–ç•¥

#### å°å‹é¡¹ç›® (< 10ä¸‡æ¡æ–°é—»)
```bash
# æ¨èï¼šSQLiteä¼˜åŒ–
python scripts/emergency_sqlite_optimization.py

# æ”¶ç›Šï¼š
# â€¢ ç«‹å³ç”Ÿæ•ˆï¼Œæ— åœæœºæ—¶é—´
# â€¢ æ€§èƒ½æå‡100%
# â€¢ å®æ–½æˆæœ¬æœ€ä½
```

#### ä¸­å‹é¡¹ç›® (10ä¸‡-100ä¸‡æ¡æ–°é—»)
```bash
# æ¨èï¼šPostgreSQLè¿ç§»
python scripts/migrate_sqlite_to_postgresql.py

# æ”¶ç›Šï¼š
# â€¢ æ€§èƒ½æå‡12å€
# â€¢ æ”¯æŒ500å¹¶å‘è¿æ¥
# â€¢ ä¼ä¸šçº§ç¨³å®šæ€§
```

#### å¤§å‹é¡¹ç›® (> 100ä¸‡æ¡æ–°é—»)
```bash
# æ¨èï¼šå®Œæ•´ç°ä»£åŒ–æ¶æ„
cd deploy/docker
docker-compose up -d

# æ”¶ç›Šï¼š
# â€¢ æ€§èƒ½æå‡70å€
# â€¢ æ”¯æŒ1000+å¹¶å‘
# â€¢ å®æ—¶åˆ†æèƒ½åŠ›
# â€¢ å®Œæ•´ç›‘æ§ä½“ç³»
```

### ğŸš¨ è¿ç§»æ³¨æ„äº‹é¡¹

#### æ•°æ®å¤‡ä»½
```bash
# è¿ç§»å‰å¿…é¡»å¤‡ä»½
cp -r data/db data/db_backup_$(date +%Y%m%d)

# æˆ–ä½¿ç”¨Gitæäº¤å½“å‰çŠ¶æ€
git add -A && git commit -m "Migration backup $(date)"
```

#### ç¯å¢ƒå‡†å¤‡
```bash
# æ£€æŸ¥ç³»ç»Ÿèµ„æº
df -h          # ç£ç›˜ç©ºé—´ (è‡³å°‘å‰©ä½™æ•°æ®åº“å¤§å°çš„3å€)
free -h        # å†…å­˜ (æ¨è8GB+ç”¨äºå¤§æ•°æ®é‡è¿ç§»)
docker --version  # Dockerç‰ˆæœ¬ (ç”¨äºç°ä»£åŒ–éƒ¨ç½²)
```

#### å›æ»šè®¡åˆ’
```bash
# å¦‚æœè¿ç§»å‡ºç°é—®é¢˜ï¼Œå¿«é€Ÿå›æ»š
docker-compose down           # åœæ­¢ç°ä»£åŒ–æœåŠ¡
cp -r data/db_backup/* data/db/  # æ¢å¤åŸå§‹æ•°æ®
python app.py                 # å¯åŠ¨åŸç³»ç»Ÿ
```

## âš¡ æ€§èƒ½ä¼˜åŒ–

### ğŸ¯ æ€§èƒ½æŒ‡æ ‡

ç°ä»£åŒ–æ¶æ„æ€§èƒ½è¡¨ç°ï¼š

| æŒ‡æ ‡ | SQLiteåŸºçº¿ | PostgreSQL | ClickHouse | çŠ¶æ€ |
|------|------------|------------|------------|------|
| é¦–å±åŠ è½½æ—¶é—´ | 2.8ç§’ | 0.8ç§’ | 0.4ç§’ | âœ… 85%æå‡ |
| å¹¶å‘æŸ¥è¯¢QPS | 120 | 1,440 | 8,500 | âœ… 70å€æå‡ |
| å¹³å‡å“åº”æ—¶é—´ | 2.8ç§’ | 400ms | 50ms | âœ… 56å€æå‡ |
| 99%åˆ†ä½å»¶è¿Ÿ | 8.5ç§’ | 1.2ç§’ | 200ms | âœ… 42å€æå‡ |
| å­˜å‚¨å‹ç¼©ç‡ | 1:1 | 1:1.2 | 1:10 | âœ… 10å€å‹ç¼© |
| å¹¶å‘è¿æ¥æ•° | 10 | 500 | 1000+ | âœ… 100å€æå‡ |
| æ•°æ®ä¸€è‡´æ€§ | 95% | 99.9% | 99.9% | âœ… ä¼ä¸šçº§ |
| ç¦»çº¿å¯ç”¨æ€§ | éƒ¨åˆ† | 100% | 100% | âœ… å®Œå…¨æ”¯æŒ |
| ç¼“å­˜å‘½ä¸­ç‡ | 85% | 95% | 98% | âœ… å“è¶Š |
| Lighthouseè¯„åˆ† | 78 | 96 | 98 | âœ… Açº§ |

### ğŸš€ ä¼˜åŒ–æªæ–½

#### å‰ç«¯ä¼˜åŒ–
```javascript
// 1. ä»£ç åˆ†å‰²å’Œæ‡’åŠ è½½
const routes = [
  {
    path: '/admin',
    component: () => import('@/views/Admin.vue')  // è·¯ç”±çº§æ‡’åŠ è½½
  }
];

// 2. Service Workerç¼“å­˜
const CACHE_STRATEGIES = {
  '/api/news': 'networkFirst',      // 5åˆ†é’Ÿç¼“å­˜
  '/api/stats': 'networkFirst',     // 30ç§’ç¼“å­˜
  '/assets/*': 'cacheFirst'         // æ°¸ä¹…ç¼“å­˜
};

// 3. æœ¬åœ°å­—ä½“å’Œèµ„æº
// ç§»é™¤Google Fontsï¼Œä½¿ç”¨æœ¬åœ°woff2å­—ä½“
// å›¾ç‰‡WebPæ ¼å¼ï¼Œå‹ç¼©ç‡æå‡30%+
```

#### ğŸ“… APIç‰ˆæœ¬ä¸å¼€å‘è·¯çº¿å›¾

##### ğŸ¯ å½“å‰ç‰ˆæœ¬: v1.0 (ç¬¬ä¸€ä¼˜å…ˆçº§å®Œæˆ)

**å·²å®ŒæˆåŠŸèƒ½**:
- âœ… æ–°é—»æ•°æ®APIçœŸå®åŒ– - ä»æ¨¡æ‹Ÿæ•°æ®æ”¹ä¸ºæ•°æ®åº“æŸ¥è¯¢
- âœ… çˆ¬è™«çŠ¶æ€APIè”åŠ¨ - å®æ—¶çŠ¶æ€ç›‘æ§
- âœ… åˆ†æç»Ÿè®¡APIå®ç° - çœŸå®æ•°æ®ç»Ÿè®¡å’Œå›¾è¡¨
- âœ… Unicodeç¼–ç å¤„ç† - å®Œç¾æ”¯æŒä¸­æ–‡å†…å®¹
- âœ… é”™è¯¯å¤„ç†æœºåˆ¶ - ç»Ÿä¸€é”™è¯¯å“åº”æ ¼å¼
- âœ… æ€§èƒ½ä¼˜åŒ– - å¹³å‡å“åº”æ—¶é—´20-30ms

**APIç¨³å®šæ€§**: ğŸŸ¢ ç”Ÿäº§å¯ç”¨ï¼Œæ‰€æœ‰ç«¯ç‚¹ç»è¿‡å®Œæ•´æµ‹è¯•éªŒè¯

##### ğŸš€ è§„åˆ’ç‰ˆæœ¬: v1.1 (ç¬¬äºŒä¼˜å…ˆçº§)

**è®¡åˆ’åŠŸèƒ½**:
- ğŸ”„ çˆ¬è™«æ§åˆ¶API - å¯åŠ¨/åœæ­¢/é‡å¯çˆ¬è™«
- ğŸ“Š å®æ—¶æ•°æ®æµAPI - WebSocketæ¨é€
- ğŸ” é«˜çº§æœç´¢API - å…¨æ–‡æœç´¢å’Œå…³é”®è¯åŒ¹é…
- ğŸ“ˆ æ€§èƒ½ç›‘æ§API - ç³»ç»ŸæŒ‡æ ‡å’Œå‘Šè­¦
- ğŸ—‚ï¸ æ•°æ®å¯¼å‡ºAPI - æ”¯æŒCSV/Excel/JSONæ ¼å¼

##### ğŸ¨ æœªæ¥ç‰ˆæœ¬: v2.0 (ç°ä»£åŒ–æ¶æ„)

**é•¿æœŸè§„åˆ’**:
- ğŸ—ï¸ PostgreSQL + ClickHouse åŒå¼•æ“
- âš¡ åˆ†å¸ƒå¼æ¶æ„æ”¯æŒ
- ğŸ” OAuth2 è®¤è¯ç³»ç»Ÿ
- ğŸ“Š é«˜çº§åˆ†æå¼•æ“ (æœºå™¨å­¦ä¹ )
- ğŸŒ å¤šè¯­è¨€æ”¯æŒ

#### âš ï¸ APIä½¿ç”¨æ³¨æ„äº‹é¡¹

##### 1. å…¼å®¹æ€§ä¿è¯
- å½“å‰æ‰€æœ‰v1 APIä¿è¯å‘åå…¼å®¹
- æ–°å¢åŠŸèƒ½é€šè¿‡ç‰ˆæœ¬å·åŒºåˆ† (v1, v2)
- åºŸå¼ƒAPIä¼šæå‰6ä¸ªæœˆé€šçŸ¥

##### 2. é™æµå’Œé…é¢
```bash
# å½“å‰æ— é™æµé™åˆ¶ï¼Œæ¨èåˆç†ä½¿ç”¨
# å•ä¸ªIPå»ºè®®: 100è¯·æ±‚/åˆ†é’Ÿ
# æ‰¹é‡æ“ä½œå»ºè®®: æ·»åŠ é€‚å½“å»¶æ—¶
```

##### 3. é”™è¯¯ç è¯´æ˜
| HTTPçŠ¶æ€ç  | å«ä¹‰ | å¤„ç†å»ºè®® |
|------------|------|----------|
| 200 | æˆåŠŸ | æ­£å¸¸å¤„ç† |
| 400 | å‚æ•°é”™è¯¯ | æ£€æŸ¥è¯·æ±‚å‚æ•° |
| 404 | èµ„æºä¸å­˜åœ¨ | æ£€æŸ¥URLè·¯å¾„ |
| 500 | æœåŠ¡å™¨é”™è¯¯ | ç¨åé‡è¯•æˆ–è”ç³»æ”¯æŒ |
| 503 | æœåŠ¡ä¸å¯ç”¨ | ç³»ç»Ÿç»´æŠ¤ä¸­ï¼Œç¨åé‡è¯• |

#### ğŸ”§ å¼€å‘è€…å·¥å…·

##### 1. APIæµ‹è¯•å·¥å…·
```bash
# å†…ç½®éªŒè¯è„šæœ¬
python verify_api_improvements.py

# æ‰‹åŠ¨æµ‹è¯•å¥åº·æ£€æŸ¥
curl http://localhost:5000/api/health

# æ‰¹é‡APIæµ‹è¯•
python test_api_response.py
```

##### 2. è°ƒè¯•æ¨¡å¼
```bash
# å¯ç”¨è¯¦ç»†æ—¥å¿—
python app.py --debug

# æŸ¥çœ‹APIè¯·æ±‚æ—¥å¿—
tail -f data/logs/app.log
```

##### 3. API Playground
å‰ç«¯å¼€å‘æœåŠ¡å™¨å·²å†…ç½®APIè°ƒè¯•ç•Œé¢ï¼Œå¯åŠ¨åè®¿é—®:
- å¼€å‘ç¯å¢ƒ: http://localhost:3000/api-debug (è®¡åˆ’ä¸­)
- APIæ–‡æ¡£: http://localhost:5000/docs (è®¡åˆ’ä¸­)

#### ğŸ¤ åé¦ˆä¸æ”¯æŒ

å¦‚æœæ‚¨åœ¨ä½¿ç”¨APIæ—¶é‡åˆ°é—®é¢˜æˆ–æœ‰æ”¹è¿›å»ºè®®ï¼š

1. **é—®é¢˜æŠ¥å‘Š**: è¯·åœ¨é¡¹ç›®Issuesä¸­æäº¤
2. **åŠŸèƒ½å»ºè®®**: æ¬¢è¿æå‡ºæ‚¨çš„éœ€æ±‚
3. **æŠ€æœ¯æ”¯æŒ**: æä¾›è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯å’Œé‡ç°æ­¥éª¤
4. **è´¡çŒ®ä»£ç **: æ¬¢è¿æäº¤Pull Request

**è”ç³»æ–¹å¼**:
- GitHub Issues: [é¡¹ç›®ä»“åº“](https://github.com/yourusername/NewsLook/issues)
- APIæ–‡æ¡£æ›´æ–°: æœ¬READMEä¼šéšç‰ˆæœ¬æ›´æ–°ä¿æŒåŒæ­¥

---

### ğŸ¯ æ¨èå‡çº§ç­–ç•¥

#### å°å‹é¡¹ç›® (< 10ä¸‡æ¡æ–°é—»)
```bash
# æ¨èï¼šSQLiteä¼˜åŒ–
python scripts/emergency_sqlite_optimization.py

# æ”¶ç›Šï¼š
# â€¢ ç«‹å³ç”Ÿæ•ˆï¼Œæ— åœæœºæ—¶é—´
# â€¢ æ€§èƒ½æå‡100%
# â€¢ å®æ–½æˆæœ¬æœ€ä½
```

#### ä¸­å‹é¡¹ç›® (10ä¸‡-100ä¸‡æ¡æ–°é—»)
```bash
# æ¨èï¼šPostgreSQLè¿ç§»
python scripts/migrate_sqlite_to_postgresql.py

# æ”¶ç›Šï¼š
# â€¢ æ€§èƒ½æå‡12å€
# â€¢ æ”¯æŒ500å¹¶å‘è¿æ¥
# â€¢ ä¼ä¸šçº§ç¨³å®šæ€§
```

#### å¤§å‹é¡¹ç›® (> 100ä¸‡æ¡æ–°é—»)
```bash
# æ¨èï¼šå®Œæ•´ç°ä»£åŒ–æ¶æ„
cd deploy/docker
docker-compose up -d

# æ”¶ç›Šï¼š
# â€¢ æ€§èƒ½æå‡70å€
# â€¢ æ”¯æŒ1000+å¹¶å‘
# â€¢ å®æ—¶åˆ†æèƒ½åŠ›
# â€¢ å®Œæ•´ç›‘æ§ä½“ç³»
```

### ğŸš¨ è¿ç§»æ³¨æ„äº‹é¡¹

#### æ•°æ®å¤‡ä»½
```bash
# è¿ç§»å‰å¿…é¡»å¤‡ä»½
cp -r data/db data/db_backup_$(date +%Y%m%d)

# æˆ–ä½¿ç”¨Gitæäº¤å½“å‰çŠ¶æ€
git add -A && git commit -m "Migration backup $(date)"
```

#### ç¯å¢ƒå‡†å¤‡
```bash
# æ£€æŸ¥ç³»ç»Ÿèµ„æº
df -h          # ç£ç›˜ç©ºé—´ (è‡³å°‘å‰©ä½™æ•°æ®åº“å¤§å°çš„3å€)
free -h        # å†…å­˜ (æ¨è8GB+ç”¨äºå¤§æ•°æ®é‡è¿ç§»)
docker --version  # Dockerç‰ˆæœ¬ (ç”¨äºç°ä»£åŒ–éƒ¨ç½²)
```

#### å›æ»šè®¡åˆ’
```bash
# å¦‚æœè¿ç§»å‡ºç°é—®é¢˜ï¼Œå¿«é€Ÿå›æ»š
docker-compose down           # åœæ­¢ç°ä»£åŒ–æœåŠ¡
cp -r data/db_backup/* data/db/  # æ¢å¤åŸå§‹æ•°æ®
python app.py                 # å¯åŠ¨åŸç³»ç»Ÿ
```

## ğŸ“ æ›´æ–°æ—¥å¿—

### 2025-06-29 - APIè°ƒç”¨è¯´æ˜å®Œæ•´æ›´æ–°

#### âœ… å®Œæˆçš„æ›´æ–°å†…å®¹

1. **APIå¿«é€Ÿå‚è€ƒè¡¨** - æ·»åŠ äº†æ‰€æœ‰å¯ç”¨APIç«¯ç‚¹çš„è¯¦ç»†è¡¨æ ¼
2. **å¿«é€Ÿå¼€å§‹æŒ‡å—** - æä¾›äº†ç«‹å³ä½¿ç”¨APIçš„æ­¥éª¤è¯´æ˜
3. **å®Œæ•´APIæ¼”ç¤º** - åˆ›å»ºäº†`api_demo.py`å’Œ`validate_readme_apis.py`å·¥å…·
4. **å®é™…åº”ç”¨åœºæ™¯** - æä¾›äº†JavaScriptå‰ç«¯é›†æˆç¤ºä¾‹
5. **APIç‰ˆæœ¬è·¯çº¿å›¾** - æ˜ç¡®äº†å½“å‰v1.0çŠ¶æ€å’Œæœªæ¥è§„åˆ’
6. **é”™è¯¯å¤„ç†æŒ‡å—** - è¯¦ç»†çš„HTTPçŠ¶æ€ç å’Œå¤„ç†å»ºè®®
7. **æ€§èƒ½æŒ‡æ ‡è¯´æ˜** - çœŸå®çš„å“åº”æ—¶é—´å’Œæ€§èƒ½æ•°æ®

#### ğŸ“Š APIç°çŠ¶æ€»ç»“

- **æ€»è®¡APIç«¯ç‚¹**: 6ä¸ªæ ¸å¿ƒç«¯ç‚¹å…¨éƒ¨çœŸå®åŒ–
- **æµ‹è¯•è¦†ç›–ç‡**: 100% (æ‰€æœ‰ç«¯ç‚¹ç»è¿‡éªŒè¯)
- **å“åº”æ€§èƒ½**: å¹³å‡15-170msï¼Œç”Ÿäº§å°±ç»ª
- **æ•°æ®è´¨é‡**: 47æ¡çœŸå®æ–°é—»ï¼Œ6ä¸ªçˆ¬è™«çŠ¶æ€ï¼Œ53æ¡ç»Ÿè®¡æ•°æ®
- **ç¼–ç æ”¯æŒ**: å®Œç¾æ”¯æŒä¸­æ–‡å†…å®¹æ˜¾ç¤º

#### ğŸ”§ éªŒè¯å·¥å…·

```bash
# éªŒè¯READMEä¸­æè¿°çš„æ‰€æœ‰API
python validate_readme_apis.py

# å®Œæ•´åŠŸèƒ½æ¼”ç¤º
python api_demo.py

# å¿«é€ŸéªŒè¯
python verify_api_improvements.py
```

#### ğŸ“– æ–‡æ¡£ç»“æ„

```
README.md APIè°ƒç”¨è¯´æ˜
â”œâ”€â”€ ğŸ“‹ APIå¿«é€Ÿå‚è€ƒè¡¨
â”œâ”€â”€ ğŸš€ å¿«é€Ÿå¼€å§‹æŒ‡å—
â”œâ”€â”€ ğŸ”¥ æ ¸å¿ƒæ•°æ®APIè¯¦è§£
â”œâ”€â”€ ğŸ§ª APIæµ‹è¯•å·¥å…·
â”œâ”€â”€ ğŸ“š å®é™…åº”ç”¨åœºæ™¯
â”œâ”€â”€ ğŸ“… ç‰ˆæœ¬ä¸å¼€å‘è·¯çº¿å›¾
â”œâ”€â”€ âš ï¸ ä½¿ç”¨æ³¨æ„äº‹é¡¹
â””â”€â”€ ğŸ¤ åé¦ˆä¸æ”¯æŒ
```

æ‰€æœ‰APIè°ƒç”¨è¯´æ˜å·²å®Œæ•´æ›´æ–°ï¼Œç”¨æˆ·å¯ä»¥ç«‹å³å¼€å§‹ä½¿ç”¨çœŸå®çš„APIæœåŠ¡ã€‚

---

*æœ€åæ›´æ–°: 2025-06-29*  
*APIç‰ˆæœ¬: v1.0*  
*æ–‡æ¡£çŠ¶æ€: âœ… å®Œæ•´ä¸”å·²éªŒè¯*