#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ—¥å¿—åˆ†æå·¥å…·
åˆ†æJSONæ ¼å¼çš„æ—¥å¿—æ–‡ä»¶ï¼Œç”Ÿæˆæ€§èƒ½æŠ¥å‘Šå’Œç»Ÿè®¡ä¿¡æ¯
"""

import json
import os
import sys
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
from collections import defaultdict, Counter
import argparse

# æ·»åŠ é¡¹ç›®è·¯å¾„
PROJECT_ROOT = Path(__file__).parent.parent.parent.parent.absolute()
sys.path.insert(0, str(PROJECT_ROOT))
sys.path.insert(0, str(PROJECT_ROOT / 'backend'))

try:
    from backend.newslook.core.config_manager import get_config
    from backend.newslook.core.logger_manager import get_logger
except ImportError:
    # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤è®¾ç½®
    get_config = None
    get_logger = None

class LogAnalyzer:
    """æ—¥å¿—åˆ†æå™¨"""
    
    def __init__(self, log_dir: str = None):
        """åˆå§‹åŒ–æ—¥å¿—åˆ†æå™¨"""
        if log_dir:
            self.log_dir = Path(log_dir)
        else:
            try:
                config = get_config()
                self.log_dir = Path(config.logging.file_path)
            except:
                self.log_dir = Path("logs")
        
        self.performance_data = []
        self.error_data = []
        self.general_logs = []
    
    def load_logs(self, log_file: str = "newslook.json", hours: int = 24):
        """åŠ è½½æŒ‡å®šæ—¶é—´èŒƒå›´å†…çš„æ—¥å¿—"""
        log_path = self.log_dir / log_file
        
        if not log_path.exists():
            print(f"âš ï¸  æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨: {log_path}")
            return
        
        cutoff_time = datetime.now() - timedelta(hours=hours)
        
        print(f"ğŸ“– æ­£åœ¨åˆ†ææ—¥å¿—æ–‡ä»¶: {log_path}")
        print(f"â° åˆ†ææ—¶é—´èŒƒå›´: æœ€è¿‘ {hours} å°æ—¶")
        
        try:
            with open(log_path, 'r', encoding='utf-8') as f:
                for line_num, line in enumerate(f, 1):
                    try:
                        log_entry = json.loads(line.strip())
                        
                        # è§£ææ—¶é—´æˆ³
                        timestamp_str = log_entry.get('timestamp', '')
                        try:
                            log_time = datetime.fromisoformat(timestamp_str.replace('Z', '+00:00'))
                            # ç§»é™¤æ—¶åŒºä¿¡æ¯è¿›è¡Œæ¯”è¾ƒ
                            log_time = log_time.replace(tzinfo=None)
                        except:
                            continue  # è·³è¿‡æ— æ³•è§£ææ—¶é—´çš„æ—¥å¿—
                        
                        # åªåˆ†ææŒ‡å®šæ—¶é—´èŒƒå›´å†…çš„æ—¥å¿—
                        if log_time < cutoff_time:
                            continue
                        
                        # åˆ†ç±»æ—¥å¿—
                        if 'operation' in log_entry and 'duration_ms' in log_entry:
                            self.performance_data.append(log_entry)
                        elif log_entry.get('level') in ['ERROR', 'CRITICAL']:
                            self.error_data.append(log_entry)
                        else:
                            self.general_logs.append(log_entry)
                            
                    except json.JSONDecodeError as e:
                        print(f"âš ï¸  ç¬¬{line_num}è¡ŒJSONè§£æå¤±è´¥: {e}")
                        continue
                        
        except Exception as e:
            print(f"âŒ è¯»å–æ—¥å¿—æ–‡ä»¶å¤±è´¥: {e}")
            return
        
        print(f"âœ… æ—¥å¿—åŠ è½½å®Œæˆ:")
        print(f"   æ€§èƒ½æ—¥å¿—: {len(self.performance_data)} æ¡")
        print(f"   é”™è¯¯æ—¥å¿—: {len(self.error_data)} æ¡") 
        print(f"   ä¸€èˆ¬æ—¥å¿—: {len(self.general_logs)} æ¡")
    
    def analyze_performance(self) -> Dict[str, Any]:
        """åˆ†ææ€§èƒ½æ•°æ®"""
        if not self.performance_data:
            return {"message": "æ²¡æœ‰æ€§èƒ½æ•°æ®"}
        
        # æŒ‰æ“ä½œç±»å‹åˆ†ç»„
        operations = defaultdict(list)
        categories = defaultdict(list)
        
        for entry in self.performance_data:
            op_name = entry.get('operation', 'unknown')
            duration = entry.get('duration_ms', 0)
            category = entry.get('category', 'general')
            
            operations[op_name].append(duration)
            categories[category].append(duration)
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        def calc_stats(durations):
            if not durations:
                return {}
            return {
                'count': len(durations),
                'avg': round(sum(durations) / len(durations), 2),
                'min': round(min(durations), 2),
                'max': round(max(durations), 2),
                'total': round(sum(durations), 2)
            }
        
        # åˆ†æç»“æœ
        result = {
            'total_operations': len(self.performance_data),
            'by_operation': {op: calc_stats(durs) for op, durs in operations.items()},
            'by_category': {cat: calc_stats(durs) for cat, durs in categories.items()},
            'slowest_operations': [],
            'fastest_operations': []
        }
        
        # æ‰¾å‡ºæœ€æ…¢å’Œæœ€å¿«çš„æ“ä½œ
        all_ops = [(entry.get('operation', 'unknown'), entry.get('duration_ms', 0)) 
                  for entry in self.performance_data]
        
        all_ops.sort(key=lambda x: x[1], reverse=True)
        result['slowest_operations'] = all_ops[:10]
        result['fastest_operations'] = all_ops[-10:]
        
        return result
    
    def analyze_errors(self) -> Dict[str, Any]:
        """åˆ†æé”™è¯¯æ•°æ®"""
        if not self.error_data:
            return {"message": "æ²¡æœ‰é”™è¯¯æ•°æ®"}
        
        # é”™è¯¯ç±»å‹ç»Ÿè®¡
        error_types = Counter()
        error_modules = Counter()
        error_messages = Counter()
        
        for entry in self.error_data:
            level = entry.get('level', 'UNKNOWN')
            module = entry.get('module', 'unknown')
            message = entry.get('message', 'unknown')
            
            error_types[level] += 1
            error_modules[module] += 1
            error_messages[message] += 1
        
        return {
            'total_errors': len(self.error_data),
            'by_level': dict(error_types),
            'by_module': dict(error_modules.most_common(10)),
            'common_messages': dict(error_messages.most_common(10))
        }
    
    def analyze_general_activity(self) -> Dict[str, Any]:
        """åˆ†æä¸€èˆ¬æ´»åŠ¨"""
        if not self.general_logs:
            return {"message": "æ²¡æœ‰ä¸€èˆ¬æ—¥å¿—æ•°æ®"}
        
        # æ—¥å¿—çº§åˆ«ç»Ÿè®¡
        levels = Counter()
        modules = Counter()
        hourly_activity = defaultdict(int)
        
        for entry in self.general_logs:
            level = entry.get('level', 'UNKNOWN')
            module = entry.get('module', 'unknown')
            timestamp_str = entry.get('timestamp', '')
            
            levels[level] += 1
            modules[module] += 1
            
            # æŒ‰å°æ—¶ç»Ÿè®¡æ´»åŠ¨
            try:
                log_time = datetime.fromisoformat(timestamp_str.replace('Z', '+00:00'))
                hour_key = log_time.strftime('%Y-%m-%d %H:00')
                hourly_activity[hour_key] += 1
            except:
                pass
        
        return {
            'total_logs': len(self.general_logs),
            'by_level': dict(levels),
            'by_module': dict(modules.most_common(10)),
            'hourly_activity': dict(hourly_activity)
        }
    
    def generate_report(self) -> str:
        """ç”Ÿæˆå®Œæ•´çš„åˆ†ææŠ¥å‘Š"""
        report = []
        report.append("=" * 60)
        report.append("NewsLook æ—¥å¿—åˆ†ææŠ¥å‘Š")
        report.append("=" * 60)
        report.append(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append(f"æ—¥å¿—ç›®å½•: {self.log_dir}")
        report.append("")
        
        # æ€§èƒ½åˆ†æ
        perf_analysis = self.analyze_performance()
        report.append("ğŸ“Š æ€§èƒ½åˆ†æ")
        report.append("-" * 40)
        
        if 'message' in perf_analysis:
            report.append(f"   {perf_analysis['message']}")
        else:
            report.append(f"   æ€»æ“ä½œæ•°: {perf_analysis['total_operations']}")
            
            # æŒ‰ç±»åˆ«ç»Ÿè®¡
            report.append("\n   ğŸ“ˆ æŒ‰ç±»åˆ«ç»Ÿè®¡:")
            for category, stats in perf_analysis['by_category'].items():
                report.append(f"     {category}: {stats['count']}æ¬¡, å¹³å‡{stats['avg']}ms")
            
            # æœ€æ…¢æ“ä½œ
            report.append("\n   ğŸŒ æœ€æ…¢æ“ä½œ (å‰5):")
            for i, (op, duration) in enumerate(perf_analysis['slowest_operations'][:5], 1):
                report.append(f"     {i}. {op}: {duration}ms")
        
        report.append("")
        
        # é”™è¯¯åˆ†æ
        error_analysis = self.analyze_errors()
        report.append("âŒ é”™è¯¯åˆ†æ")
        report.append("-" * 40)
        
        if 'message' in error_analysis:
            report.append(f"   {error_analysis['message']}")
        else:
            report.append(f"   æ€»é”™è¯¯æ•°: {error_analysis['total_errors']}")
            
            report.append("\n   ğŸ“Š æŒ‰çº§åˆ«ç»Ÿè®¡:")
            for level, count in error_analysis['by_level'].items():
                report.append(f"     {level}: {count}")
            
            report.append("\n   ğŸ“ æŒ‰æ¨¡å—ç»Ÿè®¡ (å‰5):")
            for module, count in list(error_analysis['by_module'].items())[:5]:
                report.append(f"     {module}: {count}")
        
        report.append("")
        
        # æ´»åŠ¨åˆ†æ
        activity_analysis = self.analyze_general_activity()
        report.append("ğŸ“‹ æ´»åŠ¨åˆ†æ")
        report.append("-" * 40)
        
        if 'message' in activity_analysis:
            report.append(f"   {activity_analysis['message']}")
        else:
            report.append(f"   æ€»æ—¥å¿—æ•°: {activity_analysis['total_logs']}")
            
            report.append("\n   ğŸ“Š æŒ‰çº§åˆ«ç»Ÿè®¡:")
            for level, count in activity_analysis['by_level'].items():
                report.append(f"     {level}: {count}")
        
        report.append("")
        report.append("=" * 60)
        
        return "\n".join(report)
    
    def save_report(self, filename: str = None):
        """ä¿å­˜åˆ†ææŠ¥å‘Šåˆ°æ–‡ä»¶"""
        if not filename:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"log_analysis_report_{timestamp}.txt"
        
        report_path = self.log_dir / filename
        report_content = self.generate_report()
        
        try:
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write(report_content)
            print(f"âœ… åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")
        except Exception as e:
            print(f"âŒ ä¿å­˜æŠ¥å‘Šå¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='NewsLook æ—¥å¿—åˆ†æå·¥å…·')
    parser.add_argument('--log-dir', help='æ—¥å¿—ç›®å½•è·¯å¾„')
    parser.add_argument('--log-file', default='newslook.json', help='æ—¥å¿—æ–‡ä»¶å')
    parser.add_argument('--hours', type=int, default=24, help='åˆ†ææœ€è¿‘Nå°æ—¶çš„æ—¥å¿—')
    parser.add_argument('--save', action='store_true', help='ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶')
    parser.add_argument('--output', help='è¾“å‡ºæ–‡ä»¶å')
    
    args = parser.parse_args()
    
    # åˆ›å»ºåˆ†æå™¨
    analyzer = LogAnalyzer(args.log_dir)
    
    # åŠ è½½æ—¥å¿—
    analyzer.load_logs(args.log_file, args.hours)
    
    # ç”Ÿæˆå¹¶æ˜¾ç¤ºæŠ¥å‘Š
    report = analyzer.generate_report()
    print(report)
    
    # ä¿å­˜æŠ¥å‘Šï¼ˆå¦‚æœæŒ‡å®šï¼‰
    if args.save:
        analyzer.save_report(args.output)

if __name__ == '__main__':
    main() 