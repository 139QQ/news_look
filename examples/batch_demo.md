# NewsLook 批量爬虫演示 - 使用指南

## 简介

`batch_demo.py` 是 NewsLook 财经新闻爬虫系统的批量处理演示脚本，专为多数据源的并行爬取设计。该脚本利用线程池实现了多个新闻源的并发爬取，并提供了统一的结果汇总和报告功能，适合需要从多个财经网站批量采集数据的场景。

## 功能亮点

- 支持并行爬取多个新闻源
- 可自定义并发工作线程数量
- 提供详细的爬取统计和汇总报告
- 自动保存爬取结果到JSON文件
- 灵活的命令行参数配置

## 支持的数据源

- 东方财富
- 新浪财经
- 网易财经
- 凤凰财经

## 使用方法

### 命令行参数

```
python examples/batch_demo.py [选项]
```

| 参数 | 说明 | 默认值 | 可选值 |
|------|------|--------|--------|
| --sources | 要爬取的数据源列表 | 全部可用源 | 东方财富, 新浪财经, 网易财经, 凤凰财经 |
| --days | 爬取天数 | 1 | 任意正整数 |
| --max | 每个源最大爬取新闻数量 | 20 | 任意正整数 |
| --workers | 并发工作线程数 | 4 | 任意正整数 |
| --out-dir | 输出目录 | data/batch_demo | 任意有效目录路径 |

### 使用示例

1. 使用默认参数爬取所有支持的新闻源：
```
python examples/batch_demo.py
```

2. 指定爬取东方财富和新浪财经两个源，近3天的新闻：
```
python examples/batch_demo.py --sources 东方财富 新浪财经 --days 3
```

3. 爬取网易财经和凤凰财经，每个源最多50条新闻，使用6个工作线程：
```
python examples/batch_demo.py --sources 网易财经 凤凰财经 --max 50 --workers 6
```

4. 指定自定义输出目录：
```
python examples/batch_demo.py --out-dir ./my_news_data
```

## 输出内容

执行脚本后会输出：

1. 批处理配置信息（数据源、天数、最大新闻数等）
2. 每个源的爬取开始和完成状态
3. 每个源的爬取结果统计（成功数、失败数、总时间）
4. 最终的汇总报告（总爬取数量、总成功率、总耗时）

### 生成的文件

1. 每个源的爬取结果JSON文件：`{输出目录}/{源名称}_{时间戳}.json`
2. 汇总报告JSON文件：`{输出目录}/summary_{时间戳}.json`

## 批量爬虫工作原理

1. **初始化**：创建输出目录，设置日志记录器
2. **源分配**：将每个源分配给线程池中的一个工作线程
3. **并行执行**：每个工作线程独立处理一个新闻源的爬取任务
4. **结果汇总**：所有爬取任务完成后，收集各个源的统计信息并生成汇总报告

## 性能调优建议

- 根据系统配置和网络状况调整 `--workers` 参数
- 对于性能较低的系统，建议降低并发线程数和每个源的最大新闻数
- 对于网络条件较好的环境，可以适当增加工作线程数提高总体效率

## 注意事项

1. 批量爬取可能会增加被目标网站限制的风险，请合理设置爬取参数
2. 增加工作线程数会提高CPU和内存使用率，请根据系统资源合理配置
3. 脚本会自动创建输出目录，无需手动创建
4. 为避免重复爬取，每次运行会生成带有时间戳的唯一文件名
5. 请遵守各网站的爬虫政策和使用条款 