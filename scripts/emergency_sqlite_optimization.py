#!/usr/bin/env python3
"""
SQLiteç´§æ€¥ä¼˜åŒ–è„šæœ¬
ç«‹å³ç¼“è§£é”äº‰ç”¨å’Œå¹¶å‘ç“¶é¢ˆé—®é¢˜

ä½¿ç”¨æ–¹æ³•:
python scripts/emergency_sqlite_optimization.py
"""

import os
import sys
import time
import logging
from pathlib import Path
from typing import List

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from backend.newslook.core.sqlite_optimizer import get_sqlite_optimizer

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    handlers=[
        logging.FileHandler('data/logs/sqlite_optimization.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

def discover_sqlite_databases() -> List[str]:
    """å‘ç°é¡¹ç›®ä¸­çš„æ‰€æœ‰SQLiteæ•°æ®åº“æ–‡ä»¶"""
    data_dir = project_root / "data"
    db_files = []
    
    # æœç´¢æ¨¡å¼
    patterns = ["*.db", "*.sqlite", "*.sqlite3"]
    
    for pattern in patterns:
        db_files.extend(data_dir.rglob(pattern))
    
    # è¿‡æ»¤æ‰å¤‡ä»½æ–‡ä»¶å’Œæµ‹è¯•æ–‡ä»¶
    filtered_files = []
    for db_file in db_files:
        file_name = db_file.name.lower()
        if not any(skip in file_name for skip in ['backup', 'bak', 'temp', 'tmp', 'test']):
            filtered_files.append(str(db_file))
    
    return filtered_files

def main():
    """ä¸»æ‰§è¡Œå‡½æ•°"""
    print("ğŸš¨ NewsLook SQLiteç´§æ€¥ä¼˜åŒ–ç¨‹åºå¯åŠ¨")
    print("=" * 60)
    
    start_time = time.time()
    optimizer = get_sqlite_optimizer()
    
    try:
        # 1. å‘ç°æ‰€æœ‰æ•°æ®åº“æ–‡ä»¶
        print("ğŸ“Š æ­£åœ¨å‘ç°æ•°æ®åº“æ–‡ä»¶...")
        db_files = discover_sqlite_databases()
        
        if not db_files:
            print("âŒ æœªå‘ç°ä»»ä½•SQLiteæ•°æ®åº“æ–‡ä»¶")
            return
            
        print(f"âœ… å‘ç° {len(db_files)} ä¸ªæ•°æ®åº“æ–‡ä»¶:")
        for db_file in db_files:
            size_mb = Path(db_file).stat().st_size / 1024 / 1024
            print(f"   - {db_file} ({size_mb:.2f} MB)")
        
        print("\n" + "=" * 60)
        
        # 2. ç«‹å³å¯ç”¨WALæ¨¡å¼
        print("ğŸ”§ æ­£åœ¨ä¸ºæ‰€æœ‰æ•°æ®åº“å¯ç”¨WALæ¨¡å¼...")
        wal_results = optimizer.enable_wal_mode_for_all(db_files)
        
        print(f"âœ… WALæ¨¡å¼å¯ç”¨æˆåŠŸ: {len(wal_results['success'])} ä¸ª")
        print(f"âŒ WALæ¨¡å¼å¯ç”¨å¤±è´¥: {len(wal_results['failed'])} ä¸ª")
        
        if wal_results['failed']:
            print("å¤±è´¥è¯¦æƒ…:")
            for failed in wal_results['failed']:
                print(f"   - {failed}")
        
        print("\n" + "=" * 60)
        
        # 3. æ”¶é›†ä¼˜åŒ–å‰çš„ç»Ÿè®¡ä¿¡æ¯
        print("ğŸ“ˆ æ­£åœ¨æ”¶é›†æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯...")
        stats_before = []
        for db_file in db_files:
            stats = optimizer.get_database_stats(db_file)
            stats_before.append(stats)
            if 'error' not in stats:
                print(f"   - {Path(db_file).name}: {stats['size_mb']:.2f}MB, {stats['journal_mode']} æ¨¡å¼")
        
        print("\n" + "=" * 60)
        
        # 4. æ‰§è¡Œæ•°æ®åº“ä¼˜åŒ–
        print("âš¡ æ­£åœ¨å¹¶è¡Œä¼˜åŒ–æ‰€æœ‰æ•°æ®åº“...")
        optimization_results = optimizer.optimize_all_databases(db_files)
        
        # 5. æ±‡æ€»ç»“æœ
        print("\n" + "=" * 60)
        print("ğŸ“Š ä¼˜åŒ–ç»“æœæ±‡æ€»:")
        
        successful = [r for r in optimization_results if r.get('status') == 'success']
        failed = [r for r in optimization_results if r.get('status') == 'error']
        
        print(f"âœ… æˆåŠŸä¼˜åŒ–: {len(successful)} ä¸ªæ•°æ®åº“")
        print(f"âŒ ä¼˜åŒ–å¤±è´¥: {len(failed)} ä¸ªæ•°æ®åº“")
        
        total_time_saved = 0
        total_size_reduction = 0
        
        for result in successful:
            if 'before' in result and 'after' in result:
                size_before = result['before']['size_mb']
                size_after = result['after']['size_mb']
                size_reduction = size_before - size_after
                total_size_reduction += size_reduction
                
                print(f"   ğŸ“ {Path(result['db_path']).name}:")
                print(f"      â±ï¸  ä¼˜åŒ–è€—æ—¶: {result['optimization_time']:.2f}s")
                print(f"      ğŸ’¾ å¤§å°å˜åŒ–: {size_before:.2f}MB â†’ {size_after:.2f}MB")
                if size_reduction > 0:
                    print(f"      ğŸ“‰ èŠ‚çœç©ºé—´: {size_reduction:.2f}MB")
                
                total_time_saved += result['optimization_time']
        
        if failed:
            print("\nâŒ ä¼˜åŒ–å¤±è´¥çš„æ•°æ®åº“:")
            for result in failed:
                print(f"   - {result.get('db_path', 'Unknown')}: {result.get('message', 'Unknown error')}")
        
        # 6. ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Š
        total_time = time.time() - start_time
        
        print("\n" + "=" * 60)
        print("ğŸ“‹ ä¼˜åŒ–æ€»ç»“:")
        print(f"   ğŸ•’ æ€»è€—æ—¶: {total_time:.2f}ç§’")
        print(f"   ğŸ’¾ æ€»è®¡èŠ‚çœç©ºé—´: {total_size_reduction:.2f}MB")
        print(f"   âš¡ é¢„æœŸæ€§èƒ½æå‡: æŸ¥è¯¢å»¶è¿Ÿâ†“60-80%, å¹¶å‘è¿æ¥â†‘5-10X")
        
        # 7. ä¿å­˜ä¼˜åŒ–æŠ¥å‘Š
        report_file = project_root / "data/logs/sqlite_optimization_report.txt"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(f"SQLiteç´§æ€¥ä¼˜åŒ–æŠ¥å‘Š\n")
            f.write(f"ä¼˜åŒ–æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"æ€»è€—æ—¶: {total_time:.2f}ç§’\n")
            f.write(f"ä¼˜åŒ–æ–‡ä»¶æ•°: {len(db_files)}\n")
            f.write(f"æˆåŠŸ: {len(successful)}, å¤±è´¥: {len(failed)}\n")
            f.write(f"èŠ‚çœç©ºé—´: {total_size_reduction:.2f}MB\n\n")
            
            f.write("è¯¦ç»†ç»“æœ:\n")
            for result in optimization_results:
                f.write(f"{result}\n")
        
        print(f"ğŸ“„ ä¼˜åŒ–æŠ¥å‘Šå·²ä¿å­˜è‡³: {report_file}")
        
        print("\nğŸ‰ SQLiteç´§æ€¥ä¼˜åŒ–å®Œæˆï¼")
        print("ğŸ’¡ ä¸‹ä¸€æ­¥å»ºè®®:")
        print("   1. ç›‘æ§åº”ç”¨æ€§èƒ½å˜åŒ–")
        print("   2. å‡†å¤‡PostgreSQLè¿ç§»ç¯å¢ƒ")
        print("   3. æ‰§è¡Œæ•°æ®è¿ç§»è„šæœ¬")
        
    except Exception as e:
        logger.error(f"ä¼˜åŒ–è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        print(f"âŒ ä¼˜åŒ–å¤±è´¥: {e}")
        
    finally:
        # æ¸…ç†èµ„æº
        optimizer.close_all_pools()

if __name__ == "__main__":
    main() 