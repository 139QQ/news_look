#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
NewsLook æ•°æ®è°±ç³»åˆå§‹åŒ–è„šæœ¬
è®¾ç½®æ•°æ®åº“è¡¨ç»“æ„å’Œç¤ºä¾‹æ•°æ®
"""

import sys
import os
import sqlite3
import asyncio
from datetime import datetime, timedelta
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from backend.newslook.core.data_lineage_manager import DataLineageManager
from backend.newslook.core.lineage_tracker import get_lineage_tracker
from backend.newslook.core.config_manager import ConfigManager

class DataLineageSetup:
    """æ•°æ®è°±ç³»åˆå§‹åŒ–å™¨"""
    
    def __init__(self):
        self.config_manager = ConfigManager()
        self.lineage_manager = DataLineageManager(self.config_manager)
        self.db_path = os.path.join(project_root, 'data/db/finance_news.db')
        
    def create_lineage_tables(self):
        """åˆ›å»ºæ•°æ®è°±ç³»ç›¸å…³è¡¨"""
        print("ğŸ”§ åˆ›å»ºæ•°æ®è°±ç³»è¡¨ç»“æ„...")
        
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                # åˆ›å»ºæ•°æ®è¡€ç¼˜è¡¨
                cursor.execute('''
                CREATE TABLE IF NOT EXISTS data_lineage (
                    lineage_id TEXT PRIMARY KEY,
                    source_system TEXT NOT NULL,
                    source_table TEXT NOT NULL,
                    source_field TEXT,
                    target_system TEXT NOT NULL,
                    target_table TEXT NOT NULL,
                    target_field TEXT,
                    transformation_rule TEXT,
                    transformation_type TEXT,
                    created_by TEXT DEFAULT 'system',
                    created_at TEXT DEFAULT CURRENT_TIMESTAMP,
                    metadata TEXT
                )
                ''')
                
                # åˆ›å»ºç´¢å¼•
                cursor.execute('''
                CREATE INDEX IF NOT EXISTS idx_lineage_source 
                ON data_lineage(source_system, source_table, source_field)
                ''')
                
                cursor.execute('''
                CREATE INDEX IF NOT EXISTS idx_lineage_target 
                ON data_lineage(target_system, target_table, target_field)
                ''')
                
                cursor.execute('''
                CREATE INDEX IF NOT EXISTS idx_lineage_type 
                ON data_lineage(transformation_type)
                ''')
                
                cursor.execute('''
                CREATE INDEX IF NOT EXISTS idx_lineage_created 
                ON data_lineage(created_at)
                ''')
                
                # åˆ›å»ºæ•°æ®è´¨é‡è§„åˆ™è¡¨
                cursor.execute('''
                CREATE TABLE IF NOT EXISTS quality_rules (
                    rule_id TEXT PRIMARY KEY,
                    rule_name TEXT NOT NULL,
                    rule_type TEXT NOT NULL,
                    target_table TEXT NOT NULL,
                    target_field TEXT,
                    rule_config TEXT,
                    severity TEXT DEFAULT 'WARNING',
                    is_active INTEGER DEFAULT 1,
                    created_at TEXT DEFAULT CURRENT_TIMESTAMP
                )
                ''')
                
                # åˆ›å»ºè´¨é‡æ£€æŸ¥ç»“æœè¡¨
                cursor.execute('''
                CREATE TABLE IF NOT EXISTS quality_check_results (
                    check_id TEXT PRIMARY KEY,
                    rule_id TEXT NOT NULL,
                    table_name TEXT NOT NULL,
                    batch_id TEXT,
                    total_records INTEGER,
                    passed_records INTEGER,
                    failed_records INTEGER,
                    pass_rate REAL,
                    check_time TEXT DEFAULT CURRENT_TIMESTAMP,
                    error_details TEXT,
                    FOREIGN KEY (rule_id) REFERENCES quality_rules(rule_id)
                )
                ''')
                
                # åˆ›å»ºæ•°æ®å˜æ›´æ—¥å¿—è¡¨
                cursor.execute('''
                CREATE TABLE IF NOT EXISTS data_change_logs (
                    change_id TEXT PRIMARY KEY,
                    table_name TEXT NOT NULL,
                    record_id TEXT,
                    operation TEXT NOT NULL,
                    old_values TEXT,
                    new_values TEXT,
                    changed_by TEXT DEFAULT 'system',
                    change_source TEXT,
                    changed_at TEXT DEFAULT CURRENT_TIMESTAMP
                )
                ''')
                
                conn.commit()
                print("âœ… æ•°æ®è°±ç³»è¡¨ç»“æ„åˆ›å»ºå®Œæˆ")
                
        except Exception as e:
            print(f"âŒ åˆ›å»ºè¡¨ç»“æ„å¤±è´¥: {str(e)}")
            raise
    
    async def setup_sample_lineage_data(self):
        """è®¾ç½®ç¤ºä¾‹è¡€ç¼˜æ•°æ®"""
        print("ğŸ“Š åˆ›å»ºç¤ºä¾‹æ•°æ®è¡€ç¼˜å…³ç³»...")
        
        try:
            # 1. çˆ¬è™«æ•°æ®æºè¡€ç¼˜
            crawler_mappings = [
                {
                    'source_name': 'æ–°æµªè´¢ç»',
                    'source_url': 'https://finance.sina.com.cn',
                    'field_mapping': {
                        'title': 'title',
                        'content': 'content',
                        'time': 'pub_time',
                        'link': 'url',
                        'author': 'author'
                    }
                },
                {
                    'source_name': 'ç½‘æ˜“è´¢ç»',
                    'source_url': 'https://money.163.com',
                    'field_mapping': {
                        'headline': 'title',
                        'body': 'content',
                        'publish_time': 'pub_time',
                        'source_url': 'url'
                    }
                },
                {
                    'source_name': 'è…¾è®¯è´¢ç»',
                    'source_url': 'https://finance.qq.com',
                    'field_mapping': {
                        'news_title': 'title',
                        'news_content': 'content',
                        'news_time': 'pub_time',
                        'news_url': 'url'
                    }
                }
            ]
            
            for mapping in crawler_mappings:
                await self.lineage_manager.record_crawler_lineage(
                    source_name=mapping['source_name'],
                    source_url=mapping['source_url'],
                    target_table='news_data',
                    field_mapping=mapping['field_mapping'],
                    crawler_type='web_crawler'
                )
            
            # 2. æ•°æ®è½¬æ¢è¡€ç¼˜
            transformation_mappings = [
                {
                    'source_table': 'news_data',
                    'target_table': 'news_cleaned',
                    'transformation_type': 'æ•°æ®æ¸…æ´—',
                    'field_mappings': [
                        {'source_field': 'title', 'target_field': 'clean_title', 'transform_logic': 'å»é™¤HTMLæ ‡ç­¾å’Œç‰¹æ®Šå­—ç¬¦'},
                        {'source_field': 'content', 'target_field': 'clean_content', 'transform_logic': 'å†…å®¹å»é‡å’Œæ ¼å¼åŒ–'},
                        {'source_field': 'pub_time', 'target_field': 'standard_time', 'transform_logic': 'æ—¶é—´æ ¼å¼æ ‡å‡†åŒ–'}
                    ]
                },
                {
                    'source_table': 'news_cleaned',
                    'target_table': 'news_analyzed',
                    'transformation_type': 'æ™ºèƒ½åˆ†æ',
                    'field_mappings': [
                        {'source_field': 'clean_content', 'target_field': 'sentiment_score', 'transform_logic': 'æƒ…æ„Ÿåˆ†æç®—æ³•'},
                        {'source_field': 'clean_content', 'target_field': 'keywords', 'transform_logic': 'NLPå…³é”®è¯æå–'},
                        {'source_field': 'clean_content', 'target_field': 'related_stocks', 'transform_logic': 'è‚¡ç¥¨å…³è”åº¦åˆ†æ'}
                    ]
                }
            ]
            
            for mapping in transformation_mappings:
                await self.lineage_manager.record_transformation_lineage(
                    source_table=mapping['source_table'],
                    target_table=mapping['target_table'],
                    transformation_type=mapping['transformation_type'],
                    transformation_rule=f"è‡ªåŠ¨åŒ–{mapping['transformation_type']}æµç¨‹",
                    field_mappings=mapping['field_mappings']
                )
            
            # 3. APIè®¿é—®è¡€ç¼˜  
            api_access_examples = [
                {
                    'endpoint': '/api/news/list',
                    'source_table': 'news_analyzed',
                    'query_fields': ['title', 'sentiment_score', 'pub_time']
                },
                {
                    'endpoint': '/api/news/search',
                    'source_table': 'news_analyzed',
                    'query_fields': ['title', 'content', 'keywords']
                },
                {
                    'endpoint': '/api/stocks/news',
                    'source_table': 'news_analyzed',
                    'query_fields': ['related_stocks', 'sentiment_score', 'title']
                }
            ]
            
            for api_example in api_access_examples:
                await self.lineage_manager.record_api_access_lineage(
                    api_endpoint=api_example['endpoint'],
                    source_table=api_example['source_table'],
                    query_fields=api_example['query_fields'],
                    client_info={
                        'client_ip': '127.0.0.1',
                        'user_agent': 'NewsLook-Frontend/1.0',
                        'access_type': 'sample_data'
                    }
                )
            
            print("âœ… ç¤ºä¾‹æ•°æ®è¡€ç¼˜å…³ç³»åˆ›å»ºå®Œæˆ")
            
        except Exception as e:
            print(f"âŒ åˆ›å»ºç¤ºä¾‹è¡€ç¼˜æ•°æ®å¤±è´¥: {str(e)}")
            raise
    
    async def test_lineage_queries(self):
        """æµ‹è¯•è¡€ç¼˜æŸ¥è¯¢åŠŸèƒ½"""
        print("ğŸ§ª æµ‹è¯•æ•°æ®è°±ç³»æŸ¥è¯¢åŠŸèƒ½...")
        
        try:
            # æµ‹è¯•è¡¨è¡€ç¼˜æŸ¥è¯¢
            print("\nğŸ“‹ æµ‹è¯•è¡¨è¡€ç¼˜æŸ¥è¯¢:")
            lineage_data = await self.lineage_manager.get_lineage_by_table('news_data', 'both')
            print(f"  - news_dataè¡¨æœ‰ {len(lineage_data.get('upstream', []))} ä¸ªä¸Šæ¸¸æ•°æ®æº")
            print(f"  - news_dataè¡¨æœ‰ {len(lineage_data.get('downstream', []))} ä¸ªä¸‹æ¸¸å¤„ç†")
            
            # æµ‹è¯•å½±å“åˆ†æ
            print("\nğŸ¯ æµ‹è¯•å½±å“åˆ†æ:")
            impact_data = await self.lineage_manager.analyze_impact('news_data', 'title', 3)
            print(f"  - titleå­—æ®µå˜æ›´ä¼šå½±å“ {impact_data.get('total_affected_count', 0)} ä¸ªå¯¹è±¡")
            print(f"  - æ¶‰åŠç³»ç»Ÿ: {', '.join(impact_data.get('affected_systems', []))}")
            
            # æµ‹è¯•æŠ¥å‘Šç”Ÿæˆ
            print("\nğŸ“Š æµ‹è¯•æŠ¥å‘Šç”Ÿæˆ:")
            report = await self.lineage_manager.generate_lineage_report()
            stats = report.get('statistics', {})
            print(f"  - æ€»è¡€ç¼˜å…³ç³»æ•°: {stats.get('total_lineage_relations', 0)}")
            print(f"  - æ¶‰åŠæºè¡¨æ•°: {stats.get('unique_source_tables', 0)}")
            print(f"  - æ¶‰åŠç›®æ ‡è¡¨æ•°: {stats.get('unique_target_tables', 0)}")
            
            print("âœ… æ•°æ®è°±ç³»æŸ¥è¯¢åŠŸèƒ½æµ‹è¯•é€šè¿‡")
            
        except Exception as e:
            print(f"âŒ æ•°æ®è°±ç³»æŸ¥è¯¢æµ‹è¯•å¤±è´¥: {str(e)}")
            raise
    
    def setup_quality_rules(self):
        """è®¾ç½®æ•°æ®è´¨é‡è§„åˆ™"""
        print("ğŸ“ è®¾ç½®æ•°æ®è´¨é‡è§„åˆ™...")
        
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                quality_rules = [
                    {
                        'rule_id': 'rule_news_title_not_null',
                        'rule_name': 'æ–°é—»æ ‡é¢˜éç©ºæ£€æŸ¥',
                        'rule_type': 'NOT_NULL',
                        'target_table': 'news_data',
                        'target_field': 'title',
                        'rule_config': '{"required": true}',
                        'severity': 'ERROR'
                    },
                    {
                        'rule_id': 'rule_news_url_unique',
                        'rule_name': 'æ–°é—»URLå”¯ä¸€æ€§æ£€æŸ¥',
                        'rule_type': 'UNIQUE',
                        'target_table': 'news_data',
                        'target_field': 'url',
                        'rule_config': '{"unique_key": "url"}',
                        'severity': 'ERROR'
                    },
                    {
                        'rule_id': 'rule_pub_time_range',
                        'rule_name': 'å‘å¸ƒæ—¶é—´èŒƒå›´æ£€æŸ¥',
                        'rule_type': 'RANGE',
                        'target_table': 'news_data',
                        'target_field': 'pub_time',
                        'rule_config': '{"min_date": "2020-01-01", "max_date": "2030-12-31"}',
                        'severity': 'WARNING'
                    },
                    {
                        'rule_id': 'rule_content_length',
                        'rule_name': 'å†…å®¹é•¿åº¦æ£€æŸ¥',
                        'rule_type': 'RANGE',
                        'target_table': 'news_data',
                        'target_field': 'content',
                        'rule_config': '{"min_length": 10, "max_length": 50000}',
                        'severity': 'WARNING'
                    }
                ]
                
                for rule in quality_rules:
                    cursor.execute('''
                    INSERT OR REPLACE INTO quality_rules (
                        rule_id, rule_name, rule_type, target_table, target_field,
                        rule_config, severity, is_active, created_at
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, 1, ?)
                    ''', (
                        rule['rule_id'], rule['rule_name'], rule['rule_type'],
                        rule['target_table'], rule['target_field'], rule['rule_config'],
                        rule['severity'], datetime.now().isoformat()
                    ))
                
                conn.commit()
                print(f"âœ… å·²è®¾ç½® {len(quality_rules)} ä¸ªæ•°æ®è´¨é‡è§„åˆ™")
                
        except Exception as e:
            print(f"âŒ è®¾ç½®è´¨é‡è§„åˆ™å¤±è´¥: {str(e)}")
            raise
    
    def print_summary(self):
        """æ‰“å°åˆå§‹åŒ–æ€»ç»“"""
        print("\n" + "="*60)
        print("ğŸ‰ NewsLook æ•°æ®è°±ç³»åˆå§‹åŒ–å®Œæˆ!")
        print("="*60)
        print("âœ… å·²å®Œæˆçš„è®¾ç½®:")
        print("   ğŸ“‹ æ•°æ®è¡€ç¼˜è¡¨ç»“æ„")
        print("   ğŸ“Š ç¤ºä¾‹è¡€ç¼˜å…³ç³»æ•°æ®")
        print("   ğŸ“ æ•°æ®è´¨é‡è§„åˆ™")
        print("   ğŸ§ª åŠŸèƒ½æµ‹è¯•éªŒè¯")
        print("\nğŸš€ ä½¿ç”¨æ–¹æ³•:")
        print("   1. åœ¨çˆ¬è™«ä¸­ä½¿ç”¨ @track_crawler() è£…é¥°å™¨")
        print("   2. åœ¨APIä¸­ä½¿ç”¨ @track_api() è£…é¥°å™¨")
        print("   3. è®¿é—® /api/lineage/* æŸ¥çœ‹è¡€ç¼˜å…³ç³»")
        print("   4. ä½¿ç”¨ DataLineageManager è¿›è¡Œé«˜çº§æŸ¥è¯¢")
        print("\nğŸ“š æ–‡æ¡£ä½ç½®:")
        print("   - backend/newslook/core/data_lineage_manager.py")
        print("   - backend/newslook/core/lineage_tracker.py")
        print("   - backend/newslook/core/lineage_api.py")

async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”§ NewsLook æ•°æ®è°±ç³»åˆå§‹åŒ–å¼€å§‹...")
    
    setup = DataLineageSetup()
    
    try:
        # 1. åˆ›å»ºè¡¨ç»“æ„
        setup.create_lineage_tables()
        
        # 2. è®¾ç½®è´¨é‡è§„åˆ™
        setup.setup_quality_rules()
        
        # 3. åˆ›å»ºç¤ºä¾‹è¡€ç¼˜æ•°æ®
        await setup.setup_sample_lineage_data()
        
        # 4. æµ‹è¯•åŠŸèƒ½
        await setup.test_lineage_queries()
        
        # 5. æ‰“å°æ€»ç»“
        setup.print_summary()
        
    except Exception as e:
        print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {str(e)}")
        return False
    
    return True

if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1) 