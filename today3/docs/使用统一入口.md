# 财经新闻爬虫系统 - 统一入口使用说明

本文档介绍如何使用统一入口运行财经新闻爬虫系统的各种功能。

## 统一入口简介

我们已经将系统的所有功能整合到一个统一的入口文件 `run.py` 中，这个文件支持三种运行模式：
- 爬虫模式 (crawler)
- 调度模式 (scheduler)
- Web应用模式 (web)

如果不指定运行模式，系统默认会以Web应用模式启动。

## 环境变量设置

系统使用以下环境变量来配置各个组件：

| 环境变量 | 说明 | 默认值 |
| --- | --- | --- |
| `LOG_LEVEL` | 日志级别 | INFO |
| `LOG_DIR` | 日志目录 | ./logs |
| `DB_DIR` | 数据库目录 | ./data/db |

这些环境变量会在程序启动时自动设置。如果需要手动设置，可以：

- Windows：
  ```
  set DB_DIR=./data/db
  set LOG_DIR=./logs
  set LOG_LEVEL=DEBUG
  ```

- Linux/Mac：
  ```
  export DB_DIR=./data/db
  export LOG_DIR=./logs
  export LOG_LEVEL=DEBUG
  ```

## 目录结构

应用需要以下目录结构才能正常运行：

```
project_root/
├── run.py               # 统一入口
├── start.bat            # Windows启动脚本
├── start.sh             # Linux/Mac启动脚本
├── logs/                # 日志目录
├── data/                # 数据目录
│   ├── db/              # 数据库目录
│   └── output/          # 输出目录
└── app/                 # 应用代码
```

所有这些目录在启动时会自动创建，也可以使用启动脚本提前创建。

## 基本使用方法

### 1. 爬虫模式

爬虫模式用于爬取新闻数据，支持多种爬虫来源。

```bash
# 基本用法
python run.py crawler

# 指定爬虫来源
python run.py crawler --source 东方财富

# 指定爬取最近几天的新闻
python run.py crawler --source 东方财富 --days 3

# 使用代理
python run.py crawler --source 东方财富 --use-proxy

# 指定数据库路径
python run.py crawler --source 东方财富 --db-path ./data/custom_db.db

# 调试模式
python run.py crawler --source 东方财富 --debug
```

#### 爬虫模式参数

| 参数 | 说明 | 默认值 |
| --- | --- | --- |
| `--source`, `-s` | 爬虫来源 | 无（爬取所有来源） |
| `--days`, `-d` | 爬取最近几天的新闻 | 1 |
| `--use-proxy`, `-p` | 是否使用代理 | 否 |
| `--db-path` | 数据库路径 | ./data/news.db |
| `--source-db` | 是否使用来源专用数据库 | 否 |
| `--log-level` | 日志级别 | INFO |
| `--log-dir` | 日志存储目录 | ./logs |
| `--output-dir` | 输出文件目录 | ./data/output |
| `--max-news` | 每个分类最多爬取多少条新闻 | 10 |
| `--categories` | 要爬取的新闻分类 | 财经,股票 |
| `--debug` | 是否开启调试模式 | 否 |

### 2. 调度模式

调度模式用于定时执行爬虫任务。

```bash
# 基本用法
python run.py scheduler

# 以守护进程方式运行
python run.py scheduler --daemon

# 指定配置文件
python run.py scheduler --config ./config/scheduler.json

# 指定日志级别
python run.py scheduler --log-level DEBUG

# 列出所有可用的调度任务
python run.py scheduler --list-tasks
```

#### 调度模式参数

| 参数 | 说明 | 默认值 |
| --- | --- | --- |
| `--daemon` | 以守护进程方式运行 | 否 |
| `--config` | 指定配置文件路径 | 无 |
| `--log-level` | 日志级别 | INFO |
| `--log-dir` | 日志存储目录 | ./logs |
| `--task` | 指定要执行的任务名称 | 无（执行所有任务） |
| `--list-tasks` | 列出所有可用的调度任务 | 否 |

### 3. Web应用模式

Web应用模式提供一个Web界面来查看和管理爬虫任务。

```bash
# 基本用法（默认模式）
python run.py

# 显式指定Web模式
python run.py web

# 指定主机和端口
python run.py web --host 127.0.0.1 --port 8080

# 开启调试模式
python run.py web --debug

# 生产环境模式
python run.py web --prod

# 带爬虫管理器启动
python run.py web --with-crawler
```

#### Web应用模式参数

| 参数 | 说明 | 默认值 |
| --- | --- | --- |
| `--host` | 监听主机 | 0.0.0.0 |
| `--port` | 监听端口 | 5000 |
| `--debug` | 启用调试模式 | 否 |
| `--prod` | 启用生产模式（禁用调试） | 否 |
| `--log-level` | 日志级别 | INFO |
| `--log-dir` | 日志存储目录 | ./logs |
| `--with-crawler` | 启动时初始化爬虫管理器 | 否 |

## 启动脚本

为了方便使用，我们提供了启动脚本：

### Windows 环境

```batch
start.bat
```

### Linux/Mac 环境

```bash
chmod +x start.sh
./start.sh
```

## 注意事项

1. **日志文件**：所有运行产生的日志都存储在 `logs` 目录下，按日期和模块分类。

2. **数据库文件**：默认使用 `data/news.db` 作为数据库文件，可以通过参数指定其他路径。

3. **环境检查**：启动脚本会自动检查环境并创建必要的目录，确保 `data/db` 和 `logs` 目录存在。

4. **调试模式**：在调试模式下，日志级别会设置为DEBUG，会输出更详细的日志信息。

5. **生产模式**：在生产模式下，会禁用调试功能，提高安全性和性能。

## 常见问题排除

### 1. KeyError: 'DB_DIR' 错误

如果遇到 `KeyError: 'DB_DIR'` 错误，这意味着程序无法找到数据库目录的配置。解决方法：

1. 确保在运行程序前已设置 `DB_DIR` 环境变量，或者在启动脚本中设置：

   Windows:
   ```batch
   set "DB_DIR=%cd%\data\db"
   ```
   
   Linux/Mac:
   ```bash
   export DB_DIR="$(pwd)/data/db"
   ```

2. 检查 `data/db` 目录是否存在，如果不存在，请手动创建：

   Windows:
   ```batch
   mkdir data\db
   ```
   
   Linux/Mac:
   ```bash
   mkdir -p data/db
   ```

3. 使用最新版本的启动脚本，新版本已自动处理这个问题。

### 2. 无法连接到数据库

如果遇到数据库连接错误：

1. 检查 `data/db` 目录权限是否正确
2. 对于SQLite数据库，确保 `data/db/news.db` 文件可读写
3. 对于MySQL/PostgreSQL等远程数据库，检查连接信息是否正确，以及网络连接是否正常

### 3. 日志目录问题

如果遇到日志相关的错误：

1. 确保 `logs` 目录存在且有写入权限
2. 检查 `LOG_DIR` 环境变量是否正确设置

对于其他问题，请参阅 [Web应用启动说明](./web应用启动说明.md) 中的常见问题部分。 